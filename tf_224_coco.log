(u'correspondence', u'0')
(u'init_ckpt', u'/srv/glusterfs/xieya/tf_224_1/models/model.ckpt-476000')
(u'g_repeat', u'1')
(u'is_coco', u'1')
(u'with_cap_prior', u'0')
(u'with_caption', u'0')
(u'restore_opt', u'1')
(u'sampler', u'0')
(u'd_repeat', u'1')
(u'prior_boost', u'1')
(u'cap_prior_gamma', u'0.4')
(u'is_gan', u'0')
(u'batch_size', u'32')
(u'gan', u'0')
(u'is_rgb', u'0')
(u'use_vg', u'0')
(u'image_size', u'224')
(u'gpus', u'0')
(u'kernel_zero', u'0')
(u'gp_lambda', u'10')
(u'k', u'1')
(u'g_version', u'1')
(u'unet', u'0')
(u'version', u'11')
(u'temp_trainable', u'0')
(u'alpha', u'0.01')
(u'weight_decay', u'1e-3')
Using prior boost.
Training without captions.
Training without caption priors.
Learning rate G: 2e-06 D: 0.0001
Adversarial weight 0.01
Generator version 1
Discriminator version 11
Gradient penalty 10.0.
Gradient norm 1.0.
Using mscoco.
Solver initialization done.
Language solver.
Session configured.
Graph constructed.
<tf.Variable 'G/conv_1/weights:0' shape=(3, 3, 1, 64) dtype=float32_ref>
<tf.Variable 'G/conv_1/biases:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'G/conv_2/weights:0' shape=(3, 3, 64, 64) dtype=float32_ref>
<tf.Variable 'G/conv_2/biases:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'G/bn_1/beta:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'G/bn_1/gamma:0' shape=(64,) dtype=float32_ref>
<tf.Variable 'G/conv_3/weights:0' shape=(3, 3, 64, 128) dtype=float32_ref>
<tf.Variable 'G/conv_3/biases:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'G/conv_4/weights:0' shape=(3, 3, 128, 128) dtype=float32_ref>
<tf.Variable 'G/conv_4/biases:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'G/bn_2/beta:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'G/bn_2/gamma:0' shape=(128,) dtype=float32_ref>
<tf.Variable 'G/conv_5/weights:0' shape=(3, 3, 128, 256) dtype=float32_ref>
<tf.Variable 'G/conv_5/biases:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/conv_6/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>
<tf.Variable 'G/conv_6/biases:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/conv_7/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>
<tf.Variable 'G/conv_7/biases:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/bn_3/beta:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/bn_3/gamma:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/conv_8/weights:0' shape=(3, 3, 256, 512) dtype=float32_ref>
<tf.Variable 'G/conv_8/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_9/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_9/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_10/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_10/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_4/beta:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_4/gamma:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_11/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_11/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_12/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_12/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_13/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_13/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_5/beta:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_5/gamma:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_14/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_14/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_15/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_15/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_16/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_16/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_6/beta:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_6/gamma:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_17/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_17/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_18/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_18/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_19/weights:0' shape=(3, 3, 512, 512) dtype=float32_ref>
<tf.Variable 'G/conv_19/biases:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_7/beta:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/bn_7/gamma:0' shape=(512,) dtype=float32_ref>
<tf.Variable 'G/conv_20/weights:0' shape=(4, 4, 256, 512) dtype=float32_ref>
<tf.Variable 'G/conv_20/biases:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/conv_21/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>
<tf.Variable 'G/conv_21/biases:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/conv_22/weights:0' shape=(3, 3, 256, 256) dtype=float32_ref>
<tf.Variable 'G/conv_22/biases:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/bn_8/beta:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/bn_8/gamma:0' shape=(256,) dtype=float32_ref>
<tf.Variable 'G/conv_23/weights:0' shape=(1, 1, 256, 313) dtype=float32_ref>
<tf.Variable 'G/conv_23/biases:0' shape=(313,) dtype=float32_ref>
<tf.Variable 'regularization:0' shape=() dtype=float32_ref>
Initialized.
Init generator with /srv/glusterfs/xieya/tf_224_1/models/model.ckpt-476000.
2018-12-08 21:10:33.291078: step 0, G loss = 3.32, new loss = -7574.75, rb loss = 3.754 (3550733.5 examples/sec; 0.000 sec/batch)
Evaluation at step 0: loss 3.38241794904, rebalanced loss 3.89136763414.
2018-12-08 21:13:10.108571: step 10, G loss = 3.45, new loss = 8085.16, rb loss = 3.752 (2.0 examples/sec; 15.632 sec/batch)
2018-12-08 21:13:18.259454: step 20, G loss = 3.44, new loss = 11982.82, rb loss = 4.099 (41.3 examples/sec; 0.775 sec/batch)
2018-12-08 21:13:25.649722: step 30, G loss = 3.52, new loss = -6590.65, rb loss = 3.830 (45.7 examples/sec; 0.700 sec/batch)
2018-12-08 21:13:33.575217: step 40, G loss = 3.26, new loss = -2792.36, rb loss = 3.801 (42.9 examples/sec; 0.745 sec/batch)
2018-12-08 21:13:40.947322: step 50, G loss = 3.40, new loss = -18546.17, rb loss = 3.701 (45.9 examples/sec; 0.697 sec/batch)
2018-12-08 21:13:48.403769: step 60, G loss = 3.36, new loss = 20761.75, rb loss = 3.954 (45.5 examples/sec; 0.704 sec/batch)
2018-12-08 21:13:56.224595: step 70, G loss = 3.30, new loss = 908.54, rb loss = 3.874 (43.4 examples/sec; 0.738 sec/batch)
2018-12-08 21:14:03.826455: step 80, G loss = 3.38, new loss = -576.60, rb loss = 3.939 (44.3 examples/sec; 0.722 sec/batch)
2018-12-08 21:14:11.090781: step 90, G loss = 3.33, new loss = -22752.00, rb loss = 3.765 (46.6 examples/sec; 0.686 sec/batch)
2018-12-08 21:14:18.720062: step 100, G loss = 3.42, new loss = 3921.28, rb loss = 3.978 (44.2 examples/sec; 0.724 sec/batch)
Evaluation at step 100: loss 3.37342986266, rebalanced loss 3.86050579548.
2018-12-08 21:14:38.355725: step 110, G loss = 3.20, new loss = -10117.72, rb loss = 3.557 (16.7 examples/sec; 1.920 sec/batch)
2018-12-08 21:14:45.132824: step 120, G loss = 3.30, new loss = -3445.24, rb loss = 3.655 (49.7 examples/sec; 0.643 sec/batch)
2018-12-08 21:14:52.026771: step 130, G loss = 3.27, new loss = 2909.03, rb loss = 3.730 (48.8 examples/sec; 0.656 sec/batch)
2018-12-08 21:14:58.764028: step 140, G loss = 3.30, new loss = 20036.41, rb loss = 3.929 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:15:05.608481: step 150, G loss = 3.39, new loss = -4427.18, rb loss = 3.771 (49.1 examples/sec; 0.652 sec/batch)
2018-12-08 21:15:12.285689: step 160, G loss = 3.30, new loss = -11695.43, rb loss = 3.736 (50.4 examples/sec; 0.634 sec/batch)
2018-12-08 21:15:18.972649: step 170, G loss = 3.43, new loss = -2192.46, rb loss = 3.657 (50.5 examples/sec; 0.634 sec/batch)
2018-12-08 21:15:25.743434: step 180, G loss = 3.24, new loss = -12830.20, rb loss = 3.425 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 21:15:32.865800: step 190, G loss = 3.29, new loss = 4141.29, rb loss = 3.665 (47.9 examples/sec; 0.668 sec/batch)
2018-12-08 21:15:40.089084: step 200, G loss = 3.36, new loss = 30560.28, rb loss = 3.993 (46.7 examples/sec; 0.685 sec/batch)
Evaluation at step 200: loss 3.36585104465, rebalanced loss 3.80170932611.
2018-12-08 21:15:59.522916: step 210, G loss = 3.47, new loss = 3138.53, rb loss = 3.859 (16.8 examples/sec; 1.910 sec/batch)
2018-12-08 21:16:06.615631: step 220, G loss = 3.31, new loss = -14627.35, rb loss = 3.614 (47.5 examples/sec; 0.673 sec/batch)
2018-12-08 21:16:13.497491: step 230, G loss = 3.47, new loss = 27114.44, rb loss = 4.131 (49.0 examples/sec; 0.653 sec/batch)
2018-12-08 21:16:20.437561: step 240, G loss = 3.41, new loss = 3290.80, rb loss = 3.944 (48.9 examples/sec; 0.654 sec/batch)
2018-12-08 21:16:27.465004: step 250, G loss = 3.34, new loss = 2836.22, rb loss = 3.921 (48.3 examples/sec; 0.663 sec/batch)
2018-12-08 21:16:34.603290: step 260, G loss = 3.27, new loss = -19778.06, rb loss = 3.507 (47.2 examples/sec; 0.678 sec/batch)
2018-12-08 21:16:41.529092: step 270, G loss = 3.28, new loss = -24230.04, rb loss = 3.467 (48.9 examples/sec; 0.655 sec/batch)
2018-12-08 21:16:48.513621: step 280, G loss = 3.36, new loss = -10484.82, rb loss = 3.575 (48.3 examples/sec; 0.663 sec/batch)
2018-12-08 21:16:55.261109: step 290, G loss = 3.39, new loss = -4399.34, rb loss = 3.640 (50.0 examples/sec; 0.641 sec/batch)
2018-12-08 21:17:01.954761: step 300, G loss = 3.43, new loss = 40843.37, rb loss = 4.111 (50.5 examples/sec; 0.634 sec/batch)
Evaluation at step 300: loss 3.34747467836, rebalanced loss 3.82407719294.
2018-12-08 21:17:20.825125: step 310, G loss = 3.30, new loss = -11580.95, rb loss = 3.783 (17.2 examples/sec; 1.856 sec/batch)
2018-12-08 21:17:27.452118: step 320, G loss = 3.41, new loss = 16744.56, rb loss = 3.968 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:17:34.074800: step 330, G loss = 3.26, new loss = -19179.39, rb loss = 3.533 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:17:40.946896: step 340, G loss = 3.37, new loss = 14488.02, rb loss = 3.937 (49.0 examples/sec; 0.654 sec/batch)
2018-12-08 21:17:47.669506: step 350, G loss = 3.34, new loss = -10212.64, rb loss = 3.521 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 21:17:54.866218: step 360, G loss = 3.51, new loss = 22958.95, rb loss = 3.946 (49.0 examples/sec; 0.654 sec/batch)
2018-12-08 21:18:01.542819: step 370, G loss = 3.38, new loss = -3455.72, rb loss = 3.788 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 21:18:08.193230: step 380, G loss = 3.53, new loss = 11750.61, rb loss = 3.937 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:18:15.055958: step 390, G loss = 3.28, new loss = -17121.50, rb loss = 3.535 (49.2 examples/sec; 0.651 sec/batch)
2018-12-08 21:18:21.636797: step 400, G loss = 3.37, new loss = 91112.80, rb loss = 4.686 (51.2 examples/sec; 0.625 sec/batch)
Evaluation at step 400: loss 3.30225074291, rebalanced loss 3.71539913019.
2018-12-08 21:18:40.369269: step 410, G loss = 3.50, new loss = 30598.33, rb loss = 4.178 (17.4 examples/sec; 1.834 sec/batch)
2018-12-08 21:18:47.157771: step 420, G loss = 3.37, new loss = 2573.83, rb loss = 3.908 (49.8 examples/sec; 0.643 sec/batch)
2018-12-08 21:18:53.811116: step 430, G loss = 3.37, new loss = 2971.72, rb loss = 3.936 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 21:19:00.478546: step 440, G loss = 3.27, new loss = -23635.76, rb loss = 3.540 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 21:19:07.089782: step 450, G loss = 3.28, new loss = -11435.50, rb loss = 3.618 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 21:19:14.183791: step 460, G loss = 3.16, new loss = -14951.02, rb loss = 3.513 (47.2 examples/sec; 0.679 sec/batch)
2018-12-08 21:19:20.866779: step 470, G loss = 3.35, new loss = -22061.59, rb loss = 3.520 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 21:19:27.811657: step 480, G loss = 3.38, new loss = -3739.40, rb loss = 3.808 (48.4 examples/sec; 0.661 sec/batch)
2018-12-08 21:19:34.501878: step 490, G loss = 3.24, new loss = 17570.62, rb loss = 3.825 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 21:19:41.141866: step 500, G loss = 3.41, new loss = 25899.26, rb loss = 4.047 (50.6 examples/sec; 0.632 sec/batch)
Evaluation at step 500: loss 3.31136751175, rebalanced loss 3.72736175855.
2018-12-08 21:20:00.416530: step 510, G loss = 3.40, new loss = 15155.54, rb loss = 4.014 (16.9 examples/sec; 1.892 sec/batch)
2018-12-08 21:20:07.103015: step 520, G loss = 3.48, new loss = 20788.65, rb loss = 4.159 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 21:20:13.681714: step 530, G loss = 3.29, new loss = -4158.90, rb loss = 3.583 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 21:20:20.721684: step 540, G loss = 3.36, new loss = 11560.19, rb loss = 3.960 (47.7 examples/sec; 0.670 sec/batch)
2018-12-08 21:20:27.618109: step 550, G loss = 3.35, new loss = -9310.60, rb loss = 3.639 (48.8 examples/sec; 0.655 sec/batch)
2018-12-08 21:20:34.536637: step 560, G loss = 3.34, new loss = -7660.48, rb loss = 3.649 (48.8 examples/sec; 0.656 sec/batch)
2018-12-08 21:20:41.252352: step 570, G loss = 3.39, new loss = -8603.73, rb loss = 3.655 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:20:48.076362: step 580, G loss = 3.38, new loss = -891.96, rb loss = 3.729 (49.3 examples/sec; 0.649 sec/batch)
2018-12-08 21:20:54.948701: step 590, G loss = 3.28, new loss = -13644.71, rb loss = 3.681 (48.8 examples/sec; 0.655 sec/batch)
2018-12-08 21:21:01.710568: step 600, G loss = 3.23, new loss = -14022.67, rb loss = 3.634 (49.8 examples/sec; 0.642 sec/batch)
Evaluation at step 600: loss 3.36326544285, rebalanced loss 3.82580207984.
2018-12-08 21:21:20.777559: step 610, G loss = 3.40, new loss = 39009.14, rb loss = 4.158 (17.1 examples/sec; 1.871 sec/batch)
2018-12-08 21:21:27.488204: step 620, G loss = 3.45, new loss = 33744.88, rb loss = 4.161 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 21:21:34.530729: step 630, G loss = 3.21, new loss = -29845.69, rb loss = 3.332 (48.9 examples/sec; 0.654 sec/batch)
2018-12-08 21:21:41.550333: step 640, G loss = 3.30, new loss = -1026.25, rb loss = 3.872 (48.2 examples/sec; 0.664 sec/batch)
2018-12-08 21:21:48.301291: step 650, G loss = 3.28, new loss = -15815.95, rb loss = 3.539 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 21:21:55.095266: step 660, G loss = 3.28, new loss = -7823.02, rb loss = 3.676 (49.5 examples/sec; 0.646 sec/batch)
2018-12-08 21:22:01.899871: step 670, G loss = 3.28, new loss = -8393.38, rb loss = 3.704 (50.2 examples/sec; 0.638 sec/batch)
2018-12-08 21:22:08.663715: step 680, G loss = 3.16, new loss = -2123.47, rb loss = 3.590 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 21:22:15.587507: step 690, G loss = 3.43, new loss = 17693.11, rb loss = 4.176 (48.8 examples/sec; 0.656 sec/batch)
2018-12-08 21:22:22.267610: step 700, G loss = 3.36, new loss = 17709.27, rb loss = 4.004 (50.8 examples/sec; 0.630 sec/batch)
Evaluation at step 700: loss 3.35490815639, rebalanced loss 3.75938576063.
2018-12-08 21:22:41.095969: step 710, G loss = 3.34, new loss = 1106.89, rb loss = 3.749 (17.3 examples/sec; 1.849 sec/batch)
2018-12-08 21:22:47.883882: step 720, G loss = 3.26, new loss = -6712.53, rb loss = 3.657 (49.5 examples/sec; 0.646 sec/batch)
2018-12-08 21:22:54.611245: step 730, G loss = 3.45, new loss = 14236.75, rb loss = 4.007 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 21:23:01.394847: step 740, G loss = 3.22, new loss = -8984.63, rb loss = 3.494 (50.0 examples/sec; 0.640 sec/batch)
2018-12-08 21:23:08.424429: step 750, G loss = 3.29, new loss = 9347.25, rb loss = 3.820 (48.5 examples/sec; 0.660 sec/batch)
2018-12-08 21:23:15.453353: step 760, G loss = 3.33, new loss = 9495.34, rb loss = 3.881 (47.6 examples/sec; 0.672 sec/batch)
2018-12-08 21:23:22.287262: step 770, G loss = 3.36, new loss = -2866.78, rb loss = 3.889 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 21:23:29.481307: step 780, G loss = 3.46, new loss = 4831.49, rb loss = 4.022 (48.4 examples/sec; 0.661 sec/batch)
2018-12-08 21:23:36.574066: step 790, G loss = 3.52, new loss = -1805.62, rb loss = 3.977 (47.3 examples/sec; 0.676 sec/batch)
2018-12-08 21:23:43.541668: step 800, G loss = 3.27, new loss = -18202.52, rb loss = 3.566 (48.3 examples/sec; 0.662 sec/batch)
Evaluation at step 800: loss 3.35722719828, rebalanced loss 3.74600790342.
2018-12-08 21:24:02.151520: step 810, G loss = 3.34, new loss = -14756.77, rb loss = 3.638 (17.5 examples/sec; 1.823 sec/batch)
2018-12-08 21:24:08.936315: step 820, G loss = 3.45, new loss = -1504.70, rb loss = 3.790 (49.5 examples/sec; 0.647 sec/batch)
2018-12-08 21:24:15.652352: step 830, G loss = 3.28, new loss = 121.83, rb loss = 3.827 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 21:24:22.787601: step 840, G loss = 3.24, new loss = -10835.20, rb loss = 3.736 (47.1 examples/sec; 0.680 sec/batch)
2018-12-08 21:24:29.466411: step 850, G loss = 3.38, new loss = -14909.10, rb loss = 3.589 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 21:24:36.524718: step 860, G loss = 3.31, new loss = 1877.33, rb loss = 3.891 (47.7 examples/sec; 0.670 sec/batch)
2018-12-08 21:24:43.439891: step 870, G loss = 3.36, new loss = -10186.92, rb loss = 3.831 (48.5 examples/sec; 0.660 sec/batch)
2018-12-08 21:24:50.083653: step 880, G loss = 3.31, new loss = -2929.60, rb loss = 3.660 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 21:24:56.608199: step 890, G loss = 3.34, new loss = 20013.26, rb loss = 4.085 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:25:03.331479: step 900, G loss = 3.51, new loss = 20561.59, rb loss = 4.089 (50.6 examples/sec; 0.633 sec/batch)
Evaluation at step 900: loss 3.35932472547, rebalanced loss 3.79204126199.
2018-12-08 21:25:22.022569: step 910, G loss = 3.28, new loss = -4948.29, rb loss = 3.804 (17.4 examples/sec; 1.837 sec/batch)
2018-12-08 21:25:28.526525: step 920, G loss = 3.36, new loss = -16594.36, rb loss = 3.646 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 21:25:35.126301: step 930, G loss = 3.43, new loss = 42301.14, rb loss = 4.378 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:25:41.780307: step 940, G loss = 3.33, new loss = -1733.83, rb loss = 3.682 (50.8 examples/sec; 0.631 sec/batch)
2018-12-08 21:25:48.803571: step 950, G loss = 3.42, new loss = 29753.89, rb loss = 4.136 (47.8 examples/sec; 0.669 sec/batch)
2018-12-08 21:25:55.326679: step 960, G loss = 3.28, new loss = -8078.50, rb loss = 3.686 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 21:26:02.077268: step 970, G loss = 3.24, new loss = -15273.84, rb loss = 3.482 (50.1 examples/sec; 0.639 sec/batch)
2018-12-08 21:26:08.792043: step 980, G loss = 3.33, new loss = 327.70, rb loss = 3.763 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 21:26:15.470544: step 990, G loss = 3.42, new loss = 20031.71, rb loss = 4.144 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 21:26:22.025046: step 1000, G loss = 3.16, new loss = -12795.50, rb loss = 3.399 (51.3 examples/sec; 0.624 sec/batch)
Evaluation at step 1000: loss 3.34273857276, rebalanced loss 3.75657393138.
2018-12-08 21:26:45.575781: step 1010, G loss = 3.30, new loss = 8833.26, rb loss = 3.902 (13.8 examples/sec; 2.323 sec/batch)
2018-12-08 21:26:52.175759: step 1020, G loss = 3.31, new loss = -804.60, rb loss = 3.704 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 21:26:59.054288: step 1030, G loss = 3.47, new loss = 10339.83, rb loss = 4.047 (49.2 examples/sec; 0.650 sec/batch)
2018-12-08 21:27:05.729970: step 1040, G loss = 3.33, new loss = -2428.29, rb loss = 3.766 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:27:12.296527: step 1050, G loss = 3.24, new loss = -16402.42, rb loss = 3.357 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:27:18.848858: step 1060, G loss = 3.29, new loss = -8559.80, rb loss = 3.579 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:27:26.071038: step 1070, G loss = 3.21, new loss = 2009.86, rb loss = 3.721 (46.6 examples/sec; 0.687 sec/batch)
2018-12-08 21:27:33.043580: step 1080, G loss = 3.33, new loss = -14632.00, rb loss = 3.610 (48.2 examples/sec; 0.664 sec/batch)
2018-12-08 21:27:40.124431: step 1090, G loss = 3.29, new loss = 10792.26, rb loss = 3.798 (47.4 examples/sec; 0.676 sec/batch)
2018-12-08 21:27:46.763393: step 1100, G loss = 3.30, new loss = -15348.06, rb loss = 3.632 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 1100: loss 3.37410153548, rebalanced loss 3.83858606815.
2018-12-08 21:28:05.370216: step 1110, G loss = 3.32, new loss = -8831.64, rb loss = 3.628 (17.5 examples/sec; 1.828 sec/batch)
2018-12-08 21:28:12.003142: step 1120, G loss = 3.36, new loss = 568.99, rb loss = 3.681 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:28:18.560940: step 1130, G loss = 3.28, new loss = -16039.97, rb loss = 3.412 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:28:25.225917: step 1140, G loss = 3.08, new loss = -10487.43, rb loss = 3.478 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 21:28:32.114427: step 1150, G loss = 3.35, new loss = 7359.89, rb loss = 3.745 (49.1 examples/sec; 0.652 sec/batch)
2018-12-08 21:28:40.508377: step 1160, G loss = 3.37, new loss = -7272.37, rb loss = 3.819 (49.8 examples/sec; 0.642 sec/batch)
2018-12-08 21:28:47.232531: step 1170, G loss = 3.27, new loss = -19417.27, rb loss = 3.542 (50.0 examples/sec; 0.640 sec/batch)
2018-12-08 21:28:54.268039: step 1180, G loss = 3.33, new loss = 9646.15, rb loss = 3.920 (47.8 examples/sec; 0.670 sec/batch)
2018-12-08 21:29:00.902241: step 1190, G loss = 3.42, new loss = 29302.68, rb loss = 4.009 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:29:07.551229: step 1200, G loss = 3.41, new loss = -7957.46, rb loss = 3.832 (50.6 examples/sec; 0.633 sec/batch)
Evaluation at step 1200: loss 3.37236314615, rebalanced loss 3.78834906419.
2018-12-08 21:29:25.808783: step 1210, G loss = 3.34, new loss = 273.35, rb loss = 3.682 (17.9 examples/sec; 1.790 sec/batch)
2018-12-08 21:29:32.468112: step 1220, G loss = 3.29, new loss = 1949.45, rb loss = 3.807 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 21:29:39.595575: step 1230, G loss = 3.29, new loss = -9321.72, rb loss = 3.622 (47.4 examples/sec; 0.675 sec/batch)
2018-12-08 21:29:46.233334: step 1240, G loss = 3.13, new loss = -20598.18, rb loss = 3.246 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 21:29:52.864020: step 1250, G loss = 3.34, new loss = -13424.75, rb loss = 3.639 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:29:59.532898: step 1260, G loss = 3.36, new loss = -5785.84, rb loss = 3.698 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:30:06.167441: step 1270, G loss = 3.37, new loss = 11208.54, rb loss = 3.781 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:30:12.733791: step 1280, G loss = 3.34, new loss = -13451.17, rb loss = 3.521 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:30:19.472216: step 1290, G loss = 3.21, new loss = -6377.82, rb loss = 3.740 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 21:30:26.273476: step 1300, G loss = 3.42, new loss = -6582.18, rb loss = 3.813 (49.5 examples/sec; 0.646 sec/batch)
Evaluation at step 1300: loss 3.36351421674, rebalanced loss 3.78947203954.
2018-12-08 21:30:44.476959: step 1310, G loss = 3.30, new loss = -15483.80, rb loss = 3.666 (17.9 examples/sec; 1.788 sec/batch)
2018-12-08 21:30:51.136924: step 1320, G loss = 3.32, new loss = -19092.23, rb loss = 3.384 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 21:30:57.899387: step 1330, G loss = 3.31, new loss = -2720.92, rb loss = 3.847 (49.6 examples/sec; 0.645 sec/batch)
2018-12-08 21:31:04.647209: step 1340, G loss = 3.36, new loss = -10918.56, rb loss = 3.675 (50.0 examples/sec; 0.640 sec/batch)
2018-12-08 21:31:11.215052: step 1350, G loss = 3.29, new loss = 9475.45, rb loss = 3.863 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:31:17.739046: step 1360, G loss = 3.47, new loss = 13189.96, rb loss = 4.031 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:31:24.363361: step 1370, G loss = 3.38, new loss = -6859.25, rb loss = 3.704 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:31:31.061112: step 1380, G loss = 3.28, new loss = -16658.92, rb loss = 3.648 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:31:37.634949: step 1390, G loss = 3.40, new loss = -17747.37, rb loss = 3.653 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 21:31:44.160054: step 1400, G loss = 3.37, new loss = 14277.33, rb loss = 4.054 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 1400: loss 3.35481270949, rebalanced loss 3.74945913156.
2018-12-08 21:32:02.199917: step 1410, G loss = 3.45, new loss = 13543.11, rb loss = 4.031 (18.1 examples/sec; 1.770 sec/batch)
2018-12-08 21:32:08.980538: step 1420, G loss = 3.49, new loss = 6072.32, rb loss = 3.872 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:32:15.747738: step 1430, G loss = 3.37, new loss = 4252.35, rb loss = 3.880 (50.0 examples/sec; 0.640 sec/batch)
2018-12-08 21:32:23.288594: step 1440, G loss = 3.37, new loss = -2746.85, rb loss = 3.886 (44.3 examples/sec; 0.722 sec/batch)
2018-12-08 21:32:30.068348: step 1450, G loss = 3.47, new loss = 15975.61, rb loss = 4.087 (49.6 examples/sec; 0.645 sec/batch)
2018-12-08 21:32:36.648108: step 1460, G loss = 3.27, new loss = -5566.22, rb loss = 3.769 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 21:32:43.807427: step 1470, G loss = 3.48, new loss = 29405.41, rb loss = 4.020 (46.8 examples/sec; 0.683 sec/batch)
2018-12-08 21:32:50.429640: step 1480, G loss = 3.42, new loss = 13128.72, rb loss = 3.852 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:32:57.363910: step 1490, G loss = 3.35, new loss = -4392.69, rb loss = 3.827 (48.5 examples/sec; 0.660 sec/batch)
2018-12-08 21:33:04.057851: step 1500, G loss = 3.36, new loss = 427.32, rb loss = 3.660 (50.4 examples/sec; 0.635 sec/batch)
Evaluation at step 1500: loss 3.38947274685, rebalanced loss 3.81191566785.
2018-12-08 21:33:22.783675: step 1510, G loss = 3.41, new loss = -11967.34, rb loss = 3.475 (17.4 examples/sec; 1.841 sec/batch)
2018-12-08 21:33:29.376896: step 1520, G loss = 3.42, new loss = -5192.67, rb loss = 3.668 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 21:33:36.166157: step 1530, G loss = 3.32, new loss = 23353.79, rb loss = 3.893 (49.4 examples/sec; 0.647 sec/batch)
2018-12-08 21:33:42.737661: step 1540, G loss = 3.30, new loss = -8765.03, rb loss = 3.649 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:33:49.758687: step 1550, G loss = 3.30, new loss = -8717.58, rb loss = 3.703 (49.5 examples/sec; 0.647 sec/batch)
2018-12-08 21:33:56.369732: step 1560, G loss = 3.47, new loss = 20125.62, rb loss = 4.099 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 21:34:03.172293: step 1570, G loss = 3.30, new loss = -17506.19, rb loss = 3.679 (49.5 examples/sec; 0.647 sec/batch)
2018-12-08 21:34:09.874285: step 1580, G loss = 3.32, new loss = 6744.28, rb loss = 3.806 (50.1 examples/sec; 0.638 sec/batch)
2018-12-08 21:34:16.412850: step 1590, G loss = 3.36, new loss = -10914.77, rb loss = 3.656 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 21:34:22.999912: step 1600, G loss = 3.30, new loss = -10977.71, rb loss = 3.682 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 1600: loss 3.36347359816, rebalanced loss 3.84087388515.
2018-12-08 21:34:40.929116: step 1610, G loss = 3.19, new loss = -10575.91, rb loss = 3.583 (18.2 examples/sec; 1.760 sec/batch)
2018-12-08 21:34:47.471971: step 1620, G loss = 3.25, new loss = -18764.33, rb loss = 3.591 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 21:34:54.089430: step 1630, G loss = 3.27, new loss = -8309.07, rb loss = 3.657 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 21:35:00.785475: step 1640, G loss = 3.36, new loss = -9994.66, rb loss = 3.730 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 21:35:07.453724: step 1650, G loss = 3.36, new loss = 4807.52, rb loss = 3.792 (50.4 examples/sec; 0.634 sec/batch)
2018-12-08 21:35:14.044610: step 1660, G loss = 3.25, new loss = -11847.12, rb loss = 3.545 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:35:20.762170: step 1670, G loss = 3.50, new loss = 48404.80, rb loss = 4.325 (50.1 examples/sec; 0.639 sec/batch)
2018-12-08 21:35:27.623547: step 1680, G loss = 3.42, new loss = -8090.79, rb loss = 3.584 (49.0 examples/sec; 0.653 sec/batch)
2018-12-08 21:35:34.221314: step 1690, G loss = 3.33, new loss = -1079.10, rb loss = 3.811 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:35:40.955610: step 1700, G loss = 3.43, new loss = -6278.12, rb loss = 3.762 (49.9 examples/sec; 0.642 sec/batch)
Evaluation at step 1700: loss 3.33767185211, rebalanced loss 3.71464920839.
2018-12-08 21:35:59.473791: step 1710, G loss = 3.33, new loss = -3498.24, rb loss = 3.832 (17.6 examples/sec; 1.820 sec/batch)
2018-12-08 21:36:06.051065: step 1720, G loss = 3.34, new loss = -13255.47, rb loss = 3.680 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:36:12.703918: step 1730, G loss = 3.19, new loss = -21142.68, rb loss = 3.605 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:36:19.330514: step 1740, G loss = 3.26, new loss = -14355.82, rb loss = 3.596 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:36:26.068054: step 1750, G loss = 3.43, new loss = 25312.54, rb loss = 4.290 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 21:36:32.831487: step 1760, G loss = 3.33, new loss = -20306.19, rb loss = 3.599 (49.7 examples/sec; 0.643 sec/batch)
2018-12-08 21:36:39.418806: step 1770, G loss = 3.30, new loss = 2632.59, rb loss = 3.730 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 21:36:45.977380: step 1780, G loss = 3.19, new loss = -18730.02, rb loss = 3.415 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:36:52.521946: step 1790, G loss = 3.11, new loss = -22680.30, rb loss = 3.260 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:36:59.305843: step 1800, G loss = 3.24, new loss = -4252.57, rb loss = 3.717 (49.6 examples/sec; 0.646 sec/batch)
Evaluation at step 1800: loss 3.33408667247, rebalanced loss 3.76480867863.
2018-12-08 21:37:17.277916: step 1810, G loss = 3.29, new loss = -871.63, rb loss = 3.696 (18.1 examples/sec; 1.765 sec/batch)
2018-12-08 21:37:23.881606: step 1820, G loss = 3.32, new loss = 1389.72, rb loss = 3.665 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 21:37:30.524268: step 1830, G loss = 3.26, new loss = -11686.85, rb loss = 3.544 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:37:37.216290: step 1840, G loss = 3.20, new loss = -9235.61, rb loss = 3.533 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 21:37:43.840756: step 1850, G loss = 3.30, new loss = -5453.16, rb loss = 3.621 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 21:37:50.406499: step 1860, G loss = 3.38, new loss = 4559.05, rb loss = 3.854 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:37:56.971279: step 1870, G loss = 3.39, new loss = 231.45, rb loss = 3.617 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:38:03.767835: step 1880, G loss = 3.39, new loss = -6711.20, rb loss = 3.915 (49.7 examples/sec; 0.644 sec/batch)
2018-12-08 21:38:10.314019: step 1890, G loss = 3.43, new loss = -3820.76, rb loss = 3.874 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:38:16.812210: step 1900, G loss = 3.32, new loss = 9044.11, rb loss = 3.937 (51.9 examples/sec; 0.617 sec/batch)
Evaluation at step 1900: loss 3.31745242278, rebalanced loss 3.7661055247.
2018-12-08 21:38:34.936871: step 1910, G loss = 3.29, new loss = -16764.86, rb loss = 3.548 (18.0 examples/sec; 1.775 sec/batch)
2018-12-08 21:38:41.468170: step 1920, G loss = 3.42, new loss = 24697.80, rb loss = 4.040 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:38:48.034167: step 1930, G loss = 3.40, new loss = 61240.34, rb loss = 4.309 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:38:54.590477: step 1940, G loss = 3.47, new loss = 24572.70, rb loss = 4.144 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 21:39:01.204663: step 1950, G loss = 3.23, new loss = -316.96, rb loss = 3.785 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:39:07.996652: step 1960, G loss = 3.36, new loss = -19226.84, rb loss = 3.557 (49.6 examples/sec; 0.645 sec/batch)
2018-12-08 21:39:14.568328: step 1970, G loss = 3.34, new loss = -16392.61, rb loss = 3.712 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 21:39:21.151474: step 1980, G loss = 3.27, new loss = -1744.16, rb loss = 3.691 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:39:27.809037: step 1990, G loss = 3.23, new loss = -20537.47, rb loss = 3.589 (50.5 examples/sec; 0.634 sec/batch)
2018-12-08 21:39:34.313221: step 2000, G loss = 3.37, new loss = -6673.96, rb loss = 3.736 (51.8 examples/sec; 0.618 sec/batch)
Evaluation at step 2000: loss 3.32987715403, rebalanced loss 3.75253146489.
2018-12-08 21:39:57.092797: step 2010, G loss = 3.33, new loss = -10450.55, rb loss = 3.831 (14.3 examples/sec; 2.245 sec/batch)
2018-12-08 21:40:03.655231: step 2020, G loss = 3.29, new loss = -4019.09, rb loss = 3.616 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 21:40:10.196163: step 2030, G loss = 3.22, new loss = -4011.85, rb loss = 3.494 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:40:16.784203: step 2040, G loss = 3.36, new loss = -571.99, rb loss = 3.673 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:40:23.363052: step 2050, G loss = 3.35, new loss = -6172.11, rb loss = 3.740 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 21:40:29.838971: step 2060, G loss = 3.35, new loss = 9866.87, rb loss = 3.902 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 21:40:36.424453: step 2070, G loss = 3.33, new loss = -2417.45, rb loss = 3.681 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:40:43.004434: step 2080, G loss = 3.39, new loss = -699.15, rb loss = 3.728 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:40:49.544730: step 2090, G loss = 3.17, new loss = -16962.08, rb loss = 3.351 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 21:40:56.220278: step 2100, G loss = 3.29, new loss = -12155.22, rb loss = 3.541 (50.3 examples/sec; 0.637 sec/batch)
Evaluation at step 2100: loss 3.34524047375, rebalanced loss 3.73152711391.
2018-12-08 21:41:13.923201: step 2110, G loss = 3.46, new loss = 17055.29, rb loss = 4.120 (18.4 examples/sec; 1.738 sec/batch)
2018-12-08 21:41:20.407035: step 2120, G loss = 3.33, new loss = -15316.21, rb loss = 3.843 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 21:41:26.856419: step 2130, G loss = 3.14, new loss = -12973.79, rb loss = 3.435 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 21:41:33.377362: step 2140, G loss = 3.37, new loss = 5222.11, rb loss = 3.947 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:41:39.900532: step 2150, G loss = 3.27, new loss = -17503.29, rb loss = 3.562 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:41:46.598508: step 2160, G loss = 3.31, new loss = -6054.57, rb loss = 3.567 (50.1 examples/sec; 0.638 sec/batch)
2018-12-08 21:41:53.124355: step 2170, G loss = 3.42, new loss = 56760.09, rb loss = 4.320 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 21:41:59.744776: step 2180, G loss = 3.27, new loss = -11591.46, rb loss = 3.585 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:42:06.270960: step 2190, G loss = 3.37, new loss = -439.71, rb loss = 3.766 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:42:12.800259: step 2200, G loss = 3.46, new loss = 3466.67, rb loss = 3.941 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 2200: loss 3.36197904746, rebalanced loss 3.82117261092.
2018-12-08 21:42:30.269732: step 2210, G loss = 3.29, new loss = -9775.46, rb loss = 3.604 (18.7 examples/sec; 1.715 sec/batch)
2018-12-08 21:42:36.840071: step 2220, G loss = 3.41, new loss = 8415.06, rb loss = 4.114 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:42:43.251983: step 2230, G loss = 3.19, new loss = -14739.50, rb loss = 3.487 (52.5 examples/sec; 0.610 sec/batch)
2018-12-08 21:42:49.649871: step 2240, G loss = 3.26, new loss = -4616.67, rb loss = 3.583 (52.5 examples/sec; 0.609 sec/batch)
2018-12-08 21:42:56.142479: step 2250, G loss = 3.29, new loss = -13834.61, rb loss = 3.788 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 21:43:02.624139: step 2260, G loss = 3.26, new loss = -6107.60, rb loss = 3.696 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 21:43:09.143944: step 2270, G loss = 3.33, new loss = -5890.90, rb loss = 3.648 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 21:43:15.541617: step 2280, G loss = 3.36, new loss = -5420.98, rb loss = 3.592 (52.6 examples/sec; 0.608 sec/batch)
2018-12-08 21:43:21.926284: step 2290, G loss = 3.44, new loss = 10467.47, rb loss = 3.880 (52.6 examples/sec; 0.609 sec/batch)
2018-12-08 21:43:28.427773: step 2300, G loss = 3.40, new loss = 10622.81, rb loss = 3.911 (51.7 examples/sec; 0.619 sec/batch)
Evaluation at step 2300: loss 3.32286715508, rebalanced loss 3.71374643644.
2018-12-08 21:43:46.188502: step 2310, G loss = 3.24, new loss = -6935.31, rb loss = 3.556 (18.3 examples/sec; 1.744 sec/batch)
2018-12-08 21:43:52.955062: step 2320, G loss = 3.32, new loss = -9423.33, rb loss = 3.725 (49.6 examples/sec; 0.645 sec/batch)
2018-12-08 21:43:59.478139: step 2330, G loss = 3.34, new loss = 7397.52, rb loss = 3.833 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:44:06.020069: step 2340, G loss = 3.15, new loss = -15766.84, rb loss = 3.456 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:44:12.331729: step 2350, G loss = 3.43, new loss = -20853.03, rb loss = 3.586 (53.2 examples/sec; 0.602 sec/batch)
2018-12-08 21:44:18.845770: step 2360, G loss = 3.36, new loss = 2283.35, rb loss = 3.933 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:44:25.397938: step 2370, G loss = 3.31, new loss = 4177.31, rb loss = 3.759 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 21:44:31.925901: step 2380, G loss = 3.33, new loss = -17091.23, rb loss = 3.542 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:44:38.451967: step 2390, G loss = 3.30, new loss = -4341.77, rb loss = 3.700 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 21:44:44.924250: step 2400, G loss = 3.31, new loss = 3574.51, rb loss = 3.578 (52.0 examples/sec; 0.615 sec/batch)
Evaluation at step 2400: loss 3.30725262165, rebalanced loss 3.73584374587.
2018-12-08 21:45:02.107134: step 2410, G loss = 3.38, new loss = -7443.16, rb loss = 3.616 (19.0 examples/sec; 1.685 sec/batch)
2018-12-08 21:45:08.685340: step 2420, G loss = 3.23, new loss = -15740.35, rb loss = 3.518 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:45:15.204098: step 2430, G loss = 3.23, new loss = -9562.25, rb loss = 3.482 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 21:45:21.800457: step 2440, G loss = 3.31, new loss = -5182.21, rb loss = 3.790 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 21:45:28.323471: step 2450, G loss = 3.22, new loss = -28418.41, rb loss = 3.594 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:45:34.830279: step 2460, G loss = 3.33, new loss = -1412.06, rb loss = 3.806 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 21:45:41.447994: step 2470, G loss = 3.35, new loss = -8656.47, rb loss = 3.706 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 21:45:48.064475: step 2480, G loss = 3.43, new loss = 42130.30, rb loss = 4.219 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 21:45:54.909027: step 2490, G loss = 3.26, new loss = -549.52, rb loss = 3.721 (49.1 examples/sec; 0.652 sec/batch)
2018-12-08 21:46:01.474021: step 2500, G loss = 3.33, new loss = -9408.57, rb loss = 3.633 (51.3 examples/sec; 0.624 sec/batch)
Evaluation at step 2500: loss 3.33394241333, rebalanced loss 3.7572925806.
2018-12-08 21:46:19.077854: step 2510, G loss = 3.26, new loss = -9735.21, rb loss = 3.583 (18.5 examples/sec; 1.727 sec/batch)
2018-12-08 21:46:25.626760: step 2520, G loss = 3.27, new loss = -19988.21, rb loss = 3.424 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 21:46:32.207107: step 2530, G loss = 3.08, new loss = -18668.80, rb loss = 3.288 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:46:38.812110: step 2540, G loss = 3.50, new loss = 15247.62, rb loss = 4.111 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 21:46:45.364317: step 2550, G loss = 3.29, new loss = -1735.99, rb loss = 3.743 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:46:51.922986: step 2560, G loss = 3.39, new loss = -4935.25, rb loss = 3.743 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:46:58.603255: step 2570, G loss = 3.33, new loss = -8427.67, rb loss = 3.428 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 21:47:05.207199: step 2580, G loss = 3.35, new loss = 5398.37, rb loss = 3.818 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 21:47:11.750751: step 2590, G loss = 3.29, new loss = 25041.52, rb loss = 3.850 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:47:18.340717: step 2600, G loss = 3.32, new loss = -7523.33, rb loss = 3.607 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 2600: loss 3.36921509902, rebalanced loss 3.78732713064.
2018-12-08 21:47:36.083418: step 2610, G loss = 3.14, new loss = -11886.09, rb loss = 3.359 (18.4 examples/sec; 1.741 sec/batch)
2018-12-08 21:47:42.602009: step 2620, G loss = 3.39, new loss = 5549.53, rb loss = 3.904 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 21:47:49.137551: step 2630, G loss = 3.24, new loss = -17788.62, rb loss = 3.588 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:47:55.699180: step 2640, G loss = 3.40, new loss = -18898.99, rb loss = 3.651 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:48:02.247715: step 2650, G loss = 3.45, new loss = 6128.65, rb loss = 3.806 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:48:08.762651: step 2660, G loss = 3.13, new loss = -9935.49, rb loss = 3.342 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:48:15.287445: step 2670, G loss = 3.39, new loss = 5900.66, rb loss = 3.838 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:48:21.869641: step 2680, G loss = 3.38, new loss = 4823.13, rb loss = 3.817 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 21:48:28.428795: step 2690, G loss = 3.52, new loss = 1057.24, rb loss = 3.756 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:48:35.005734: step 2700, G loss = 3.30, new loss = 10794.43, rb loss = 3.924 (51.2 examples/sec; 0.625 sec/batch)
Evaluation at step 2700: loss 3.35143324534, rebalanced loss 3.80273715655.
2018-12-08 21:48:52.759508: step 2710, G loss = 3.33, new loss = -1333.71, rb loss = 3.884 (18.5 examples/sec; 1.733 sec/batch)
2018-12-08 21:48:59.404388: step 2720, G loss = 3.19, new loss = 16071.47, rb loss = 3.789 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 21:49:05.942232: step 2730, G loss = 3.48, new loss = -778.24, rb loss = 3.735 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:49:12.427106: step 2740, G loss = 3.48, new loss = 147.23, rb loss = 3.690 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 21:49:18.993148: step 2750, G loss = 3.32, new loss = 5138.56, rb loss = 3.698 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:49:25.615840: step 2760, G loss = 3.34, new loss = -15544.34, rb loss = 3.680 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:49:32.232287: step 2770, G loss = 3.06, new loss = -22989.94, rb loss = 3.374 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 21:49:38.856487: step 2780, G loss = 3.40, new loss = 7745.05, rb loss = 3.923 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:49:45.451234: step 2790, G loss = 3.24, new loss = -13713.33, rb loss = 3.552 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:49:51.997685: step 2800, G loss = 3.41, new loss = -21198.17, rb loss = 3.620 (51.5 examples/sec; 0.622 sec/batch)
Evaluation at step 2800: loss 3.34527929624, rebalanced loss 3.80121108691.
2018-12-08 21:50:09.661304: step 2810, G loss = 3.19, new loss = -10722.44, rb loss = 3.464 (18.5 examples/sec; 1.733 sec/batch)
2018-12-08 21:50:16.350155: step 2820, G loss = 3.42, new loss = -5428.89, rb loss = 3.576 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 21:50:22.915618: step 2830, G loss = 3.40, new loss = 5560.80, rb loss = 3.874 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:50:29.472128: step 2840, G loss = 3.14, new loss = -11504.60, rb loss = 3.492 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 21:50:36.054086: step 2850, G loss = 3.40, new loss = -15968.98, rb loss = 3.630 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 21:50:42.595637: step 2860, G loss = 3.50, new loss = -5075.50, rb loss = 3.817 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 21:50:49.192832: step 2870, G loss = 3.35, new loss = 8637.86, rb loss = 3.800 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 21:50:55.752420: step 2880, G loss = 3.31, new loss = -6451.77, rb loss = 3.523 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:51:02.344678: step 2890, G loss = 3.34, new loss = -14327.63, rb loss = 3.695 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:51:08.944113: step 2900, G loss = 3.32, new loss = -11035.19, rb loss = 3.553 (51.0 examples/sec; 0.627 sec/batch)
Evaluation at step 2900: loss 3.35088112354, rebalanced loss 3.78637778759.
2018-12-08 21:51:26.826028: step 2910, G loss = 3.31, new loss = -7548.01, rb loss = 3.745 (18.2 examples/sec; 1.756 sec/batch)
2018-12-08 21:51:33.636889: step 2920, G loss = 3.30, new loss = -10962.07, rb loss = 3.457 (49.3 examples/sec; 0.650 sec/batch)
2018-12-08 21:51:40.213836: step 2930, G loss = 3.19, new loss = -8301.72, rb loss = 3.525 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:51:46.858015: step 2940, G loss = 3.46, new loss = -827.83, rb loss = 3.716 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 21:51:53.431881: step 2950, G loss = 3.31, new loss = 4384.67, rb loss = 3.934 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:52:00.003139: step 2960, G loss = 3.36, new loss = -10092.21, rb loss = 3.680 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:52:06.683375: step 2970, G loss = 3.26, new loss = -6747.58, rb loss = 3.519 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 21:52:13.254818: step 2980, G loss = 3.32, new loss = -3552.44, rb loss = 3.666 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:52:19.715560: step 2990, G loss = 3.47, new loss = 12862.23, rb loss = 4.081 (52.2 examples/sec; 0.614 sec/batch)
2018-12-08 21:52:26.335566: step 3000, G loss = 3.25, new loss = -14746.56, rb loss = 3.500 (50.8 examples/sec; 0.630 sec/batch)
Evaluation at step 3000: loss 3.34375845591, rebalanced loss 3.78214052518.
2018-12-08 21:52:49.263331: step 3010, G loss = 3.34, new loss = -4696.98, rb loss = 3.804 (14.2 examples/sec; 2.260 sec/batch)
2018-12-08 21:52:55.826897: step 3020, G loss = 3.26, new loss = -21141.18, rb loss = 3.591 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 21:53:02.393041: step 3030, G loss = 3.27, new loss = -8881.80, rb loss = 3.615 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:53:08.911360: step 3040, G loss = 3.26, new loss = -10744.27, rb loss = 3.671 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 21:53:15.483493: step 3050, G loss = 3.56, new loss = 4801.78, rb loss = 4.012 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:53:21.983716: step 3060, G loss = 3.34, new loss = 4366.14, rb loss = 3.868 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 21:53:28.493011: step 3070, G loss = 3.47, new loss = -9097.46, rb loss = 3.899 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 21:53:35.036445: step 3080, G loss = 3.29, new loss = -7304.75, rb loss = 3.832 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 21:53:41.677544: step 3090, G loss = 3.47, new loss = -5374.85, rb loss = 3.811 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 21:53:48.189286: step 3100, G loss = 3.41, new loss = 3097.79, rb loss = 3.804 (51.7 examples/sec; 0.619 sec/batch)
Evaluation at step 3100: loss 3.38357092539, rebalanced loss 3.80344240665.
2018-12-08 21:54:05.830185: step 3110, G loss = 3.30, new loss = -10445.38, rb loss = 3.543 (18.5 examples/sec; 1.732 sec/batch)
2018-12-08 21:54:12.336885: step 3120, G loss = 3.35, new loss = 8167.40, rb loss = 3.790 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:54:18.802359: step 3130, G loss = 3.14, new loss = -26070.74, rb loss = 3.348 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 21:54:25.416318: step 3140, G loss = 3.42, new loss = 399.40, rb loss = 3.814 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 21:54:31.944666: step 3150, G loss = 3.37, new loss = 46858.08, rb loss = 4.148 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 21:54:38.504570: step 3160, G loss = 3.34, new loss = -22930.77, rb loss = 3.703 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 21:54:45.037549: step 3170, G loss = 3.34, new loss = -9829.83, rb loss = 3.622 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 21:54:51.591885: step 3180, G loss = 3.32, new loss = -11074.54, rb loss = 3.678 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 21:54:58.236262: step 3190, G loss = 3.41, new loss = 13470.26, rb loss = 4.036 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 21:55:04.864644: step 3200, G loss = 3.45, new loss = -636.94, rb loss = 3.741 (50.8 examples/sec; 0.630 sec/batch)
Evaluation at step 3200: loss 3.33968959649, rebalanced loss 3.72671861649.
2018-12-08 21:55:28.316223: step 3210, G loss = 3.37, new loss = -7409.20, rb loss = 3.630 (13.9 examples/sec; 2.310 sec/batch)
2018-12-08 21:55:37.074474: step 3220, G loss = 3.31, new loss = 22643.58, rb loss = 3.843 (37.9 examples/sec; 0.844 sec/batch)
2018-12-08 21:55:44.854771: step 3230, G loss = 3.32, new loss = 29461.27, rb loss = 3.997 (42.9 examples/sec; 0.745 sec/batch)
2018-12-08 21:55:54.186902: step 3240, G loss = 3.43, new loss = -4173.58, rb loss = 3.819 (35.5 examples/sec; 0.900 sec/batch)
2018-12-08 21:56:02.702136: step 3250, G loss = 3.34, new loss = 12291.52, rb loss = 4.001 (39.0 examples/sec; 0.820 sec/batch)
2018-12-08 21:56:11.805869: step 3260, G loss = 3.36, new loss = 405.68, rb loss = 3.889 (36.4 examples/sec; 0.878 sec/batch)
2018-12-08 21:56:20.148435: step 3270, G loss = 3.29, new loss = -16645.34, rb loss = 3.454 (40.1 examples/sec; 0.799 sec/batch)
2018-12-08 21:56:28.836751: step 3280, G loss = 3.48, new loss = 3663.81, rb loss = 4.006 (38.3 examples/sec; 0.836 sec/batch)
2018-12-08 21:56:38.006651: step 3290, G loss = 3.23, new loss = -9055.88, rb loss = 3.497 (36.1 examples/sec; 0.886 sec/batch)
2018-12-08 21:56:47.898597: step 3300, G loss = 3.25, new loss = 4303.01, rb loss = 3.709 (33.5 examples/sec; 0.954 sec/batch)
Evaluation at step 3300: loss 3.34250522455, rebalanced loss 3.78510870139.
2018-12-08 21:57:13.118633: step 3310, G loss = 3.30, new loss = -783.94, rb loss = 3.656 (12.9 examples/sec; 2.489 sec/batch)
2018-12-08 21:57:22.463840: step 3320, G loss = 3.42, new loss = 6166.33, rb loss = 3.894 (35.5 examples/sec; 0.901 sec/batch)
2018-12-08 21:57:30.889083: step 3330, G loss = 3.36, new loss = 599.36, rb loss = 3.803 (39.5 examples/sec; 0.810 sec/batch)
2018-12-08 21:57:39.041571: step 3340, G loss = 3.33, new loss = 31142.65, rb loss = 4.027 (40.8 examples/sec; 0.784 sec/batch)
2018-12-08 21:57:45.606209: step 3350, G loss = 3.28, new loss = -13225.25, rb loss = 3.575 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:57:52.170933: step 3360, G loss = 3.16, new loss = -23260.00, rb loss = 3.507 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:57:58.934726: step 3370, G loss = 3.20, new loss = -277.96, rb loss = 3.689 (49.7 examples/sec; 0.644 sec/batch)
2018-12-08 21:58:05.480852: step 3380, G loss = 3.25, new loss = -1400.87, rb loss = 3.772 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 21:58:12.235808: step 3390, G loss = 3.27, new loss = -18859.38, rb loss = 3.458 (49.7 examples/sec; 0.643 sec/batch)
2018-12-08 21:58:18.843521: step 3400, G loss = 3.39, new loss = 39862.68, rb loss = 4.032 (51.0 examples/sec; 0.627 sec/batch)
Evaluation at step 3400: loss 3.36549764474, rebalanced loss 3.82826417287.
2018-12-08 21:58:36.358944: step 3410, G loss = 3.40, new loss = 10427.30, rb loss = 3.836 (18.6 examples/sec; 1.720 sec/batch)
2018-12-08 21:58:42.925729: step 3420, G loss = 3.26, new loss = -17788.49, rb loss = 3.619 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 21:58:49.527828: step 3430, G loss = 3.27, new loss = -8186.98, rb loss = 3.658 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 21:58:56.114701: step 3440, G loss = 3.34, new loss = -9405.54, rb loss = 3.624 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 21:59:02.635481: step 3450, G loss = 3.27, new loss = -15822.67, rb loss = 3.628 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 21:59:09.210331: step 3460, G loss = 3.34, new loss = -6492.78, rb loss = 3.837 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 21:59:15.730229: step 3470, G loss = 3.32, new loss = -4378.70, rb loss = 3.822 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 21:59:22.256203: step 3480, G loss = 3.37, new loss = 6737.83, rb loss = 3.869 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 21:59:28.887101: step 3490, G loss = 3.28, new loss = 6639.36, rb loss = 3.842 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 21:59:35.492009: step 3500, G loss = 3.32, new loss = -12701.59, rb loss = 3.641 (51.0 examples/sec; 0.627 sec/batch)
Evaluation at step 3500: loss 3.38939099312, rebalanced loss 3.86755751769.
2018-12-08 21:59:53.400078: step 3510, G loss = 3.35, new loss = -720.27, rb loss = 3.624 (18.2 examples/sec; 1.758 sec/batch)
2018-12-08 22:00:00.101333: step 3520, G loss = 3.38, new loss = -4528.76, rb loss = 3.627 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 22:00:06.675990: step 3530, G loss = 3.34, new loss = 7795.16, rb loss = 3.852 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:00:13.266889: step 3540, G loss = 3.53, new loss = 26751.73, rb loss = 4.219 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:00:19.840547: step 3550, G loss = 3.38, new loss = 15990.28, rb loss = 3.760 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:00:26.415411: step 3560, G loss = 3.20, new loss = -26484.41, rb loss = 3.457 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:00:33.202090: step 3570, G loss = 3.22, new loss = -12849.79, rb loss = 3.523 (49.6 examples/sec; 0.645 sec/batch)
2018-12-08 22:00:39.741668: step 3580, G loss = 3.17, new loss = -3115.44, rb loss = 3.652 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:00:46.380700: step 3590, G loss = 3.44, new loss = 8685.49, rb loss = 4.117 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:00:52.926889: step 3600, G loss = 3.34, new loss = 854.30, rb loss = 3.687 (51.4 examples/sec; 0.622 sec/batch)
Evaluation at step 3600: loss 3.33925058047, rebalanced loss 3.76974948247.
2018-12-08 22:01:10.748531: step 3610, G loss = 3.30, new loss = -21482.26, rb loss = 3.570 (18.3 examples/sec; 1.750 sec/batch)
2018-12-08 22:01:17.339638: step 3620, G loss = 3.43, new loss = 14945.75, rb loss = 3.854 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:01:24.055815: step 3630, G loss = 3.35, new loss = -11396.63, rb loss = 3.719 (50.1 examples/sec; 0.638 sec/batch)
2018-12-08 22:01:30.660576: step 3640, G loss = 3.40, new loss = -13229.41, rb loss = 3.827 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 22:01:37.398805: step 3650, G loss = 3.30, new loss = -17534.21, rb loss = 3.610 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 22:01:44.000471: step 3660, G loss = 3.29, new loss = -14702.18, rb loss = 3.579 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:01:50.557530: step 3670, G loss = 3.43, new loss = 18514.78, rb loss = 3.970 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:01:57.083162: step 3680, G loss = 3.24, new loss = -23862.32, rb loss = 3.568 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:02:03.628352: step 3690, G loss = 3.33, new loss = -5098.07, rb loss = 3.704 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:02:10.256471: step 3700, G loss = 3.19, new loss = -18143.78, rb loss = 3.469 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 3700: loss 3.34804414908, rebalanced loss 3.79549072584.
2018-12-08 22:02:27.655481: step 3710, G loss = 3.36, new loss = -2822.28, rb loss = 3.726 (18.7 examples/sec; 1.708 sec/batch)
2018-12-08 22:02:34.072953: step 3720, G loss = 3.35, new loss = 23362.16, rb loss = 3.967 (52.4 examples/sec; 0.610 sec/batch)
2018-12-08 22:02:40.621091: step 3730, G loss = 3.47, new loss = 3438.72, rb loss = 3.881 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:02:47.152349: step 3740, G loss = 3.33, new loss = 250.97, rb loss = 3.834 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:02:53.676510: step 3750, G loss = 3.32, new loss = 10592.28, rb loss = 3.878 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:03:00.176781: step 3760, G loss = 3.35, new loss = 1826.35, rb loss = 3.822 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:03:06.719997: step 3770, G loss = 3.33, new loss = -12864.86, rb loss = 3.496 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:03:13.314744: step 3780, G loss = 3.37, new loss = 20778.37, rb loss = 4.166 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:03:19.819546: step 3790, G loss = 3.40, new loss = -10020.06, rb loss = 3.708 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:03:26.362235: step 3800, G loss = 3.30, new loss = -21216.51, rb loss = 3.500 (51.6 examples/sec; 0.621 sec/batch)
Evaluation at step 3800: loss 3.34481589794, rebalanced loss 3.79646340211.
2018-12-08 22:03:43.892079: step 3810, G loss = 3.39, new loss = -5815.47, rb loss = 3.686 (18.6 examples/sec; 1.722 sec/batch)
2018-12-08 22:03:50.383957: step 3820, G loss = 3.23, new loss = -18805.57, rb loss = 3.562 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:03:57.018851: step 3830, G loss = 3.34, new loss = -2460.16, rb loss = 3.843 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 22:04:03.481856: step 3840, G loss = 3.33, new loss = -7323.89, rb loss = 3.747 (52.1 examples/sec; 0.615 sec/batch)
2018-12-08 22:04:10.050853: step 3850, G loss = 3.36, new loss = 14048.93, rb loss = 3.846 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:04:16.589261: step 3860, G loss = 3.16, new loss = -35339.94, rb loss = 3.287 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:04:23.120035: step 3870, G loss = 3.46, new loss = 2024.64, rb loss = 3.938 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:04:29.886687: step 3880, G loss = 3.33, new loss = -12581.90, rb loss = 3.746 (49.6 examples/sec; 0.645 sec/batch)
2018-12-08 22:04:36.372705: step 3890, G loss = 3.28, new loss = -13187.16, rb loss = 3.538 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 22:04:42.904786: step 3900, G loss = 3.22, new loss = -13909.76, rb loss = 3.505 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 3900: loss 3.34750677745, rebalanced loss 3.71824192206.
2018-12-08 22:05:00.711822: step 3910, G loss = 3.46, new loss = -4245.11, rb loss = 3.610 (18.3 examples/sec; 1.748 sec/batch)
2018-12-08 22:05:07.205650: step 3920, G loss = 3.20, new loss = -5543.24, rb loss = 3.644 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:05:13.716344: step 3930, G loss = 3.19, new loss = -16695.66, rb loss = 3.432 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:05:20.231421: step 3940, G loss = 3.26, new loss = 9222.18, rb loss = 3.783 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:05:26.744293: step 3950, G loss = 3.14, new loss = -17296.77, rb loss = 3.362 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:05:33.266214: step 3960, G loss = 3.37, new loss = 7871.36, rb loss = 3.926 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:05:39.770949: step 3970, G loss = 3.27, new loss = 6382.78, rb loss = 3.784 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:05:46.348165: step 3980, G loss = 3.42, new loss = 44778.99, rb loss = 4.307 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:05:52.914799: step 3990, G loss = 3.35, new loss = -16411.96, rb loss = 3.540 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:05:59.607757: step 4000, G loss = 3.35, new loss = -17935.43, rb loss = 3.597 (50.3 examples/sec; 0.637 sec/batch)
Evaluation at step 4000: loss 3.33562274774, rebalanced loss 3.78346354961.
2018-12-08 22:09:15.797106: step 4010, G loss = 3.31, new loss = -21366.14, rb loss = 3.415 (1.6 examples/sec; 19.588 sec/batch)
2018-12-08 22:09:22.235580: step 4020, G loss = 3.46, new loss = 40904.25, rb loss = 4.204 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 22:09:28.788803: step 4030, G loss = 3.22, new loss = -13406.10, rb loss = 3.388 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:09:35.269391: step 4040, G loss = 3.45, new loss = -79.40, rb loss = 3.881 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 22:09:41.751304: step 4050, G loss = 3.27, new loss = 1043.39, rb loss = 3.566 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 22:09:48.304216: step 4060, G loss = 3.12, new loss = 3941.82, rb loss = 3.645 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:09:54.876905: step 4070, G loss = 3.35, new loss = 6987.86, rb loss = 3.760 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:10:01.402019: step 4080, G loss = 3.25, new loss = -18770.29, rb loss = 3.336 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:10:07.964413: step 4090, G loss = 3.37, new loss = 40651.93, rb loss = 4.179 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:10:14.443566: step 4100, G loss = 3.45, new loss = 41903.84, rb loss = 4.348 (52.0 examples/sec; 0.616 sec/batch)
Evaluation at step 4100: loss 3.3486317873, rebalanced loss 3.7736557881.
2018-12-08 22:10:31.791727: step 4110, G loss = 3.48, new loss = 7910.16, rb loss = 3.811 (18.8 examples/sec; 1.702 sec/batch)
2018-12-08 22:10:38.243359: step 4120, G loss = 3.30, new loss = -9759.11, rb loss = 3.570 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 22:10:44.756017: step 4130, G loss = 3.34, new loss = 12677.45, rb loss = 3.775 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:10:51.194913: step 4140, G loss = 3.47, new loss = 52418.57, rb loss = 4.146 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 22:10:57.653413: step 4150, G loss = 3.27, new loss = -14400.14, rb loss = 3.616 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 22:11:04.089757: step 4160, G loss = 3.30, new loss = -6547.15, rb loss = 3.765 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 22:11:10.570609: step 4170, G loss = 3.37, new loss = -15599.50, rb loss = 3.618 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:11:17.060198: step 4180, G loss = 3.29, new loss = -17387.28, rb loss = 3.697 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:11:23.668677: step 4190, G loss = 3.32, new loss = 8570.54, rb loss = 3.814 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 22:11:30.238326: step 4200, G loss = 3.32, new loss = 2754.15, rb loss = 3.704 (51.2 examples/sec; 0.626 sec/batch)
Evaluation at step 4200: loss 3.37729583581, rebalanced loss 3.81879132589.
2018-12-08 22:11:47.738079: step 4210, G loss = 3.26, new loss = -15939.02, rb loss = 3.582 (18.6 examples/sec; 1.719 sec/batch)
2018-12-08 22:11:54.170257: step 4220, G loss = 3.19, new loss = 6294.51, rb loss = 3.659 (52.4 examples/sec; 0.610 sec/batch)
2018-12-08 22:12:00.686342: step 4230, G loss = 3.34, new loss = -5595.95, rb loss = 3.637 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:12:07.458146: step 4240, G loss = 3.34, new loss = 2888.43, rb loss = 3.786 (49.5 examples/sec; 0.646 sec/batch)
2018-12-08 22:12:13.969650: step 4250, G loss = 3.39, new loss = 10526.29, rb loss = 3.988 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:12:20.403760: step 4260, G loss = 3.30, new loss = -17401.49, rb loss = 3.521 (52.4 examples/sec; 0.611 sec/batch)
2018-12-08 22:12:26.889041: step 4270, G loss = 3.31, new loss = 22017.81, rb loss = 4.131 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:12:33.394855: step 4280, G loss = 3.19, new loss = -15481.61, rb loss = 3.486 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:12:39.969528: step 4290, G loss = 3.28, new loss = -5438.26, rb loss = 3.739 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:12:46.585547: step 4300, G loss = 3.25, new loss = -15348.83, rb loss = 3.539 (50.8 examples/sec; 0.630 sec/batch)
Evaluation at step 4300: loss 3.30774033864, rebalanced loss 3.69937564532.
2018-12-08 22:13:04.201537: step 4310, G loss = 3.20, new loss = -13389.29, rb loss = 3.343 (18.5 examples/sec; 1.730 sec/batch)
2018-12-08 22:13:10.711687: step 4320, G loss = 3.30, new loss = 5241.87, rb loss = 3.866 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:13:17.275572: step 4330, G loss = 3.41, new loss = -3625.54, rb loss = 3.778 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:13:24.238727: step 4340, G loss = 3.28, new loss = -13189.37, rb loss = 3.739 (48.2 examples/sec; 0.664 sec/batch)
2018-12-08 22:13:30.790927: step 4350, G loss = 3.27, new loss = -2645.80, rb loss = 3.772 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:13:37.338333: step 4360, G loss = 3.33, new loss = 2999.00, rb loss = 3.772 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:13:43.878610: step 4370, G loss = 3.32, new loss = -6833.39, rb loss = 3.681 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:13:50.473410: step 4380, G loss = 3.37, new loss = 10112.59, rb loss = 3.838 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 22:13:57.003289: step 4390, G loss = 3.15, new loss = -10315.78, rb loss = 3.373 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 22:14:03.528908: step 4400, G loss = 3.15, new loss = -13472.10, rb loss = 3.552 (51.6 examples/sec; 0.621 sec/batch)
Evaluation at step 4400: loss 3.34643479188, rebalanced loss 3.80810360114.
2018-12-08 22:14:21.067782: step 4410, G loss = 3.45, new loss = 8279.69, rb loss = 3.825 (18.6 examples/sec; 1.721 sec/batch)
2018-12-08 22:14:27.593853: step 4420, G loss = 3.21, new loss = -6705.99, rb loss = 3.619 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:14:34.126625: step 4430, G loss = 3.37, new loss = -14361.82, rb loss = 3.499 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:14:40.638463: step 4440, G loss = 3.28, new loss = 3901.65, rb loss = 3.810 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:14:47.177967: step 4450, G loss = 3.28, new loss = 305.91, rb loss = 3.818 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:14:53.670110: step 4460, G loss = 3.32, new loss = -16600.09, rb loss = 3.665 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:15:00.181887: step 4470, G loss = 3.35, new loss = -3917.91, rb loss = 3.768 (51.7 examples/sec; 0.618 sec/batch)
2018-12-08 22:15:06.653119: step 4480, G loss = 3.13, new loss = -21651.17, rb loss = 3.251 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:15:13.143996: step 4490, G loss = 3.19, new loss = -11479.55, rb loss = 3.492 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:15:19.599396: step 4500, G loss = 3.28, new loss = -19059.01, rb loss = 3.418 (52.0 examples/sec; 0.615 sec/batch)
Evaluation at step 4500: loss 3.28080164591, rebalanced loss 3.73799939156.
2018-12-08 22:15:37.269303: step 4510, G loss = 3.41, new loss = 2280.15, rb loss = 3.860 (18.5 examples/sec; 1.734 sec/batch)
2018-12-08 22:15:43.782320: step 4520, G loss = 3.34, new loss = 19324.57, rb loss = 3.932 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:15:50.313959: step 4530, G loss = 3.35, new loss = 10299.04, rb loss = 3.912 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 22:15:56.873957: step 4540, G loss = 3.26, new loss = 2298.78, rb loss = 3.870 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:16:03.473373: step 4550, G loss = 3.38, new loss = 5731.92, rb loss = 3.606 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:16:10.095256: step 4560, G loss = 3.33, new loss = -5186.54, rb loss = 3.610 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:16:16.643464: step 4570, G loss = 3.32, new loss = -13414.94, rb loss = 3.673 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:16:23.179821: step 4580, G loss = 3.33, new loss = 14113.87, rb loss = 3.864 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:16:29.753260: step 4590, G loss = 3.32, new loss = 3758.63, rb loss = 3.762 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:16:36.315981: step 4600, G loss = 3.37, new loss = 1120.72, rb loss = 3.863 (51.3 examples/sec; 0.624 sec/batch)
Evaluation at step 4600: loss 3.32977747122, rebalanced loss 3.7165507555.
2018-12-08 22:16:53.950243: step 4610, G loss = 3.26, new loss = 2103.95, rb loss = 3.764 (18.5 examples/sec; 1.730 sec/batch)
2018-12-08 22:17:00.545139: step 4620, G loss = 3.31, new loss = -12785.24, rb loss = 3.526 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:17:07.134321: step 4630, G loss = 3.31, new loss = -10010.06, rb loss = 3.723 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:17:13.752272: step 4640, G loss = 3.47, new loss = 11321.93, rb loss = 3.835 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:17:20.335324: step 4650, G loss = 3.36, new loss = 808.42, rb loss = 3.585 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:17:26.924009: step 4660, G loss = 3.50, new loss = 14917.86, rb loss = 4.078 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:17:33.554448: step 4670, G loss = 3.38, new loss = 5590.77, rb loss = 4.035 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:17:40.142998: step 4680, G loss = 3.27, new loss = 12606.08, rb loss = 3.870 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:17:46.687590: step 4690, G loss = 3.37, new loss = 8878.04, rb loss = 3.727 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:17:53.460800: step 4700, G loss = 3.06, new loss = -19920.33, rb loss = 3.289 (49.5 examples/sec; 0.646 sec/batch)
Evaluation at step 4700: loss 3.34683146477, rebalanced loss 3.77785168489.
2018-12-08 22:18:10.969504: step 4710, G loss = 3.53, new loss = 5250.91, rb loss = 3.954 (18.6 examples/sec; 1.719 sec/batch)
2018-12-08 22:18:17.513496: step 4720, G loss = 3.32, new loss = 20977.81, rb loss = 4.035 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:18:24.062989: step 4730, G loss = 3.28, new loss = 5824.57, rb loss = 3.849 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:18:30.602523: step 4740, G loss = 3.30, new loss = -23680.29, rb loss = 3.558 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:18:37.116625: step 4750, G loss = 3.23, new loss = -21695.74, rb loss = 3.331 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 22:18:43.649864: step 4760, G loss = 3.17, new loss = -19161.13, rb loss = 3.392 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:18:50.175824: step 4770, G loss = 3.23, new loss = -17948.41, rb loss = 3.523 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:18:56.735635: step 4780, G loss = 3.23, new loss = -6463.09, rb loss = 3.633 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:19:03.375848: step 4790, G loss = 3.27, new loss = -6049.44, rb loss = 3.692 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:19:10.090565: step 4800, G loss = 3.32, new loss = 3914.09, rb loss = 3.772 (50.1 examples/sec; 0.639 sec/batch)
Evaluation at step 4800: loss 3.31419274807, rebalanced loss 3.74809583028.
2018-12-08 22:19:27.619773: step 4810, G loss = 3.30, new loss = -9309.62, rb loss = 3.593 (18.6 examples/sec; 1.720 sec/batch)
2018-12-08 22:19:34.252679: step 4820, G loss = 3.34, new loss = 24453.53, rb loss = 4.014 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:19:40.853159: step 4830, G loss = 3.34, new loss = 7941.31, rb loss = 3.838 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:19:47.408240: step 4840, G loss = 3.44, new loss = 24774.93, rb loss = 4.271 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:19:53.982401: step 4850, G loss = 3.37, new loss = -14644.65, rb loss = 3.703 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:20:00.547471: step 4860, G loss = 3.42, new loss = -6658.97, rb loss = 3.863 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:20:07.060040: step 4870, G loss = 3.31, new loss = -17071.83, rb loss = 3.505 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:20:13.601129: step 4880, G loss = 3.32, new loss = 13247.63, rb loss = 3.825 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:20:20.106286: step 4890, G loss = 3.36, new loss = -37.85, rb loss = 3.743 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:20:26.639165: step 4900, G loss = 3.38, new loss = 9436.19, rb loss = 3.902 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 4900: loss 3.35166219076, rebalanced loss 3.73106721242.
2018-12-08 22:20:44.191459: step 4910, G loss = 3.36, new loss = 46310.39, rb loss = 4.058 (18.6 examples/sec; 1.722 sec/batch)
2018-12-08 22:20:50.779456: step 4920, G loss = 3.27, new loss = 9207.82, rb loss = 3.778 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:20:57.285422: step 4930, G loss = 3.34, new loss = -6344.95, rb loss = 3.595 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:21:03.723211: step 4940, G loss = 3.31, new loss = -5041.06, rb loss = 3.604 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 22:21:10.280551: step 4950, G loss = 3.38, new loss = -3134.40, rb loss = 3.752 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:21:16.809127: step 4960, G loss = 3.58, new loss = 147649.92, rb loss = 5.326 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:21:23.333545: step 4970, G loss = 3.39, new loss = -2638.89, rb loss = 3.756 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:21:29.889365: step 4980, G loss = 3.33, new loss = 15845.70, rb loss = 3.954 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:21:36.331755: step 4990, G loss = 3.15, new loss = -6827.16, rb loss = 3.511 (52.4 examples/sec; 0.611 sec/batch)
2018-12-08 22:21:42.823805: step 5000, G loss = 3.42, new loss = 1745.55, rb loss = 3.864 (51.8 examples/sec; 0.617 sec/batch)
Evaluation at step 5000: loss 3.35401573976, rebalanced loss 3.80457308292.
2018-12-08 22:22:06.032847: step 5010, G loss = 3.43, new loss = -10528.60, rb loss = 3.754 (14.0 examples/sec; 2.289 sec/batch)
2018-12-08 22:22:12.686709: step 5020, G loss = 3.49, new loss = 88.24, rb loss = 3.869 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 22:22:19.170081: step 5030, G loss = 3.22, new loss = -13850.82, rb loss = 3.629 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:22:25.665848: step 5040, G loss = 3.44, new loss = -3388.96, rb loss = 3.804 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 22:22:32.209920: step 5050, G loss = 3.38, new loss = 4096.96, rb loss = 3.928 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:22:38.707294: step 5060, G loss = 3.30, new loss = -6643.87, rb loss = 3.680 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:22:45.265494: step 5070, G loss = 3.42, new loss = 16839.61, rb loss = 3.876 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:22:51.815464: step 5080, G loss = 3.31, new loss = 1972.83, rb loss = 3.763 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:22:58.307617: step 5090, G loss = 3.38, new loss = -7120.31, rb loss = 3.859 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 22:23:04.786211: step 5100, G loss = 3.39, new loss = -1435.62, rb loss = 3.768 (52.0 examples/sec; 0.616 sec/batch)
Evaluation at step 5100: loss 3.33017190297, rebalanced loss 3.70048004786.
2018-12-08 22:23:22.634133: step 5110, G loss = 3.44, new loss = 31709.45, rb loss = 4.291 (18.3 examples/sec; 1.752 sec/batch)
2018-12-08 22:23:29.198035: step 5120, G loss = 3.41, new loss = -4032.37, rb loss = 3.695 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:23:35.821997: step 5130, G loss = 3.39, new loss = 2859.41, rb loss = 3.804 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:23:42.454197: step 5140, G loss = 3.33, new loss = 9588.84, rb loss = 3.968 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:23:49.037226: step 5150, G loss = 3.26, new loss = -13990.43, rb loss = 3.497 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:23:55.604781: step 5160, G loss = 3.20, new loss = -13996.10, rb loss = 3.245 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:24:02.489196: step 5170, G loss = 3.42, new loss = -11795.27, rb loss = 3.747 (48.9 examples/sec; 0.654 sec/batch)
2018-12-08 22:24:09.057508: step 5180, G loss = 3.19, new loss = -15789.05, rb loss = 3.420 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:24:15.603858: step 5190, G loss = 3.42, new loss = 12978.10, rb loss = 3.979 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:24:22.150168: step 5200, G loss = 3.29, new loss = -18474.53, rb loss = 3.370 (51.4 examples/sec; 0.622 sec/batch)
Evaluation at step 5200: loss 3.34516955217, rebalanced loss 3.78768127759.
2018-12-08 22:24:39.591685: step 5210, G loss = 3.37, new loss = 9005.35, rb loss = 3.972 (18.7 examples/sec; 1.712 sec/batch)
2018-12-08 22:24:46.085096: step 5220, G loss = 3.23, new loss = 12271.88, rb loss = 3.707 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:24:52.560250: step 5230, G loss = 3.33, new loss = -15773.97, rb loss = 3.478 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:24:59.111545: step 5240, G loss = 3.39, new loss = 1219.32, rb loss = 3.781 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:25:05.523888: step 5250, G loss = 3.39, new loss = -6067.70, rb loss = 3.725 (52.5 examples/sec; 0.609 sec/batch)
2018-12-08 22:25:12.024115: step 5260, G loss = 3.26, new loss = -2515.05, rb loss = 3.696 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:25:18.548024: step 5270, G loss = 3.27, new loss = 5581.80, rb loss = 3.905 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:25:25.052276: step 5280, G loss = 3.21, new loss = -14093.13, rb loss = 3.549 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:25:31.575562: step 5290, G loss = 3.41, new loss = -2254.79, rb loss = 3.845 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:25:38.100558: step 5300, G loss = 3.40, new loss = 28440.72, rb loss = 4.014 (51.6 examples/sec; 0.620 sec/batch)
Evaluation at step 5300: loss 3.32297596137, rebalanced loss 3.77212665876.
2018-12-08 22:25:55.510327: step 5310, G loss = 3.19, new loss = -4074.17, rb loss = 3.522 (18.7 examples/sec; 1.710 sec/batch)
2018-12-08 22:26:02.028407: step 5320, G loss = 3.30, new loss = -12347.43, rb loss = 3.544 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:26:08.523554: step 5330, G loss = 3.34, new loss = 9268.44, rb loss = 3.815 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:26:15.026744: step 5340, G loss = 3.30, new loss = 5515.73, rb loss = 3.774 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:26:21.644064: step 5350, G loss = 3.05, new loss = -18770.84, rb loss = 3.387 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:26:28.262742: step 5360, G loss = 3.31, new loss = 5969.20, rb loss = 3.733 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:26:34.756001: step 5370, G loss = 3.23, new loss = 16132.52, rb loss = 3.841 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:26:41.199994: step 5380, G loss = 3.42, new loss = 7482.27, rb loss = 3.899 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 22:26:47.732188: step 5390, G loss = 3.44, new loss = 14350.78, rb loss = 3.866 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:26:54.295869: step 5400, G loss = 3.38, new loss = 14209.30, rb loss = 4.057 (51.2 examples/sec; 0.625 sec/batch)
Evaluation at step 5400: loss 3.33697940509, rebalanced loss 3.78973685106.
2018-12-08 22:27:11.827733: step 5410, G loss = 3.19, new loss = -15217.64, rb loss = 3.467 (18.6 examples/sec; 1.720 sec/batch)
2018-12-08 22:27:18.428507: step 5420, G loss = 3.27, new loss = -2601.33, rb loss = 3.479 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:27:25.025497: step 5430, G loss = 3.37, new loss = 24446.20, rb loss = 4.002 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:27:31.639103: step 5440, G loss = 3.37, new loss = 2963.78, rb loss = 3.711 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:27:38.175183: step 5450, G loss = 3.32, new loss = -20763.39, rb loss = 3.556 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:27:44.700023: step 5460, G loss = 3.27, new loss = -12320.79, rb loss = 3.600 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:27:51.157915: step 5470, G loss = 3.26, new loss = -9807.81, rb loss = 3.687 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 22:27:57.635913: step 5480, G loss = 3.22, new loss = -16913.24, rb loss = 3.333 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 22:28:04.246449: step 5490, G loss = 3.28, new loss = 15756.66, rb loss = 3.943 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:28:10.851726: step 5500, G loss = 3.21, new loss = -14230.91, rb loss = 3.509 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 5500: loss 3.35167496204, rebalanced loss 3.81320733229.
2018-12-08 22:28:28.475532: step 5510, G loss = 3.27, new loss = -7480.86, rb loss = 3.535 (18.5 examples/sec; 1.730 sec/batch)
2018-12-08 22:28:35.063038: step 5520, G loss = 3.22, new loss = -7068.03, rb loss = 3.633 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:28:41.546490: step 5530, G loss = 3.26, new loss = -6490.80, rb loss = 3.642 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:28:48.005490: step 5540, G loss = 3.44, new loss = -868.35, rb loss = 3.714 (52.2 examples/sec; 0.614 sec/batch)
2018-12-08 22:28:54.461364: step 5550, G loss = 3.40, new loss = 8363.65, rb loss = 3.797 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 22:29:01.103829: step 5560, G loss = 3.39, new loss = -11187.85, rb loss = 3.714 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 22:29:07.646943: step 5570, G loss = 3.40, new loss = 8675.97, rb loss = 3.980 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:29:14.154807: step 5580, G loss = 3.40, new loss = 15031.50, rb loss = 3.889 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:29:20.977072: step 5590, G loss = 3.42, new loss = 55738.43, rb loss = 4.363 (49.3 examples/sec; 0.649 sec/batch)
2018-12-08 22:29:27.631529: step 5600, G loss = 3.29, new loss = -5445.29, rb loss = 3.671 (50.5 examples/sec; 0.633 sec/batch)
Evaluation at step 5600: loss 3.34608404636, rebalanced loss 3.7876614968.
2018-12-08 22:29:45.201850: step 5610, G loss = 3.31, new loss = 2298.62, rb loss = 3.683 (18.5 examples/sec; 1.725 sec/batch)
2018-12-08 22:29:51.683849: step 5620, G loss = 3.34, new loss = -2076.67, rb loss = 3.752 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:29:58.173212: step 5630, G loss = 3.21, new loss = 7758.92, rb loss = 3.540 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:30:04.729044: step 5640, G loss = 3.38, new loss = 11584.59, rb loss = 3.812 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:30:11.283147: step 5650, G loss = 3.27, new loss = -5118.55, rb loss = 3.649 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:30:17.767306: step 5660, G loss = 3.32, new loss = 12833.10, rb loss = 3.832 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 22:30:24.288552: step 5670, G loss = 3.38, new loss = -15391.66, rb loss = 3.736 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:30:30.878034: step 5680, G loss = 3.29, new loss = -7207.51, rb loss = 3.546 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:30:37.390762: step 5690, G loss = 3.28, new loss = -13550.72, rb loss = 3.489 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:30:43.914362: step 5700, G loss = 3.23, new loss = -16407.91, rb loss = 3.449 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 5700: loss 3.35225145817, rebalanced loss 3.80880602996.
2018-12-08 22:31:01.436522: step 5710, G loss = 3.29, new loss = 8720.68, rb loss = 3.955 (18.6 examples/sec; 1.721 sec/batch)
2018-12-08 22:31:07.945989: step 5720, G loss = 3.35, new loss = -8836.95, rb loss = 3.486 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:31:14.554440: step 5730, G loss = 3.43, new loss = 33733.14, rb loss = 4.210 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:31:21.146765: step 5740, G loss = 3.38, new loss = -7861.67, rb loss = 3.787 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:31:27.757963: step 5750, G loss = 3.30, new loss = 14868.81, rb loss = 3.851 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:31:34.425643: step 5760, G loss = 3.30, new loss = 5382.81, rb loss = 3.758 (50.4 examples/sec; 0.634 sec/batch)
2018-12-08 22:31:40.943466: step 5770, G loss = 3.36, new loss = -767.49, rb loss = 3.873 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:31:47.470471: step 5780, G loss = 3.28, new loss = 30736.23, rb loss = 3.981 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:31:54.084959: step 5790, G loss = 3.31, new loss = 11970.04, rb loss = 3.894 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:32:00.715220: step 5800, G loss = 3.24, new loss = -3299.98, rb loss = 3.651 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 5800: loss 3.33937869867, rebalanced loss 3.70676707427.
2018-12-08 22:32:18.267907: step 5810, G loss = 3.39, new loss = -2243.53, rb loss = 3.606 (18.6 examples/sec; 1.723 sec/batch)
2018-12-08 22:32:24.779414: step 5820, G loss = 3.10, new loss = -21567.23, rb loss = 3.406 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:32:31.580467: step 5830, G loss = 3.19, new loss = -18983.45, rb loss = 3.540 (49.4 examples/sec; 0.647 sec/batch)
2018-12-08 22:32:38.136922: step 5840, G loss = 3.28, new loss = 15249.77, rb loss = 3.740 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:32:44.660021: step 5850, G loss = 3.28, new loss = -3040.21, rb loss = 3.737 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:32:51.481152: step 5860, G loss = 3.51, new loss = 30529.71, rb loss = 4.283 (49.3 examples/sec; 0.649 sec/batch)
2018-12-08 22:32:57.943824: step 5870, G loss = 3.23, new loss = 4023.96, rb loss = 3.726 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 22:33:04.521484: step 5880, G loss = 3.44, new loss = 17656.78, rb loss = 4.059 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:33:11.112505: step 5890, G loss = 3.29, new loss = -9690.19, rb loss = 3.551 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:33:17.626828: step 5900, G loss = 3.22, new loss = -20724.15, rb loss = 3.420 (51.7 examples/sec; 0.619 sec/batch)
Evaluation at step 5900: loss 3.35451455116, rebalanced loss 3.74673240185.
2018-12-08 22:33:35.320174: step 5910, G loss = 3.40, new loss = -3092.26, rb loss = 3.796 (18.4 examples/sec; 1.737 sec/batch)
2018-12-08 22:33:41.843229: step 5920, G loss = 3.33, new loss = -8564.77, rb loss = 3.731 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:33:48.396129: step 5930, G loss = 3.34, new loss = -7370.85, rb loss = 3.685 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:33:54.974692: step 5940, G loss = 3.29, new loss = -3333.00, rb loss = 3.671 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:34:01.622229: step 5950, G loss = 3.44, new loss = 27158.24, rb loss = 4.135 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 22:34:08.162205: step 5960, G loss = 3.49, new loss = 25024.35, rb loss = 3.955 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:34:14.700860: step 5970, G loss = 3.32, new loss = -7601.06, rb loss = 3.725 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:34:21.281746: step 5980, G loss = 3.43, new loss = 14375.55, rb loss = 3.973 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:34:27.854704: step 5990, G loss = 3.32, new loss = 6655.33, rb loss = 3.827 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:34:34.407230: step 6000, G loss = 3.34, new loss = -8175.30, rb loss = 3.661 (51.4 examples/sec; 0.623 sec/batch)
Evaluation at step 6000: loss 3.33137922287, rebalanced loss 3.7556497256.
2018-12-08 22:34:57.872632: step 6010, G loss = 3.42, new loss = 8228.82, rb loss = 3.909 (13.8 examples/sec; 2.315 sec/batch)
2018-12-08 22:35:04.464174: step 6020, G loss = 3.44, new loss = 15494.62, rb loss = 3.939 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:35:11.012292: step 6030, G loss = 3.30, new loss = -13181.05, rb loss = 3.573 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:35:17.579769: step 6040, G loss = 3.32, new loss = -4198.09, rb loss = 3.697 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:35:24.163271: step 6050, G loss = 3.31, new loss = -9680.94, rb loss = 3.659 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:35:30.800259: step 6060, G loss = 3.34, new loss = -3097.83, rb loss = 3.673 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:35:37.389575: step 6070, G loss = 3.54, new loss = 39248.16, rb loss = 4.289 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:35:43.968563: step 6080, G loss = 3.31, new loss = -7866.04, rb loss = 3.579 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:35:50.503995: step 6090, G loss = 3.21, new loss = -24018.30, rb loss = 3.397 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 22:35:57.150045: step 6100, G loss = 3.35, new loss = 6650.45, rb loss = 3.710 (50.6 examples/sec; 0.632 sec/batch)
Evaluation at step 6100: loss 3.33917720318, rebalanced loss 3.71336979071.
2018-12-08 22:36:14.839194: step 6110, G loss = 3.39, new loss = 4467.82, rb loss = 3.941 (18.4 examples/sec; 1.736 sec/batch)
2018-12-08 22:36:21.425729: step 6120, G loss = 3.40, new loss = 17842.27, rb loss = 3.892 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:36:28.005464: step 6130, G loss = 3.41, new loss = -24399.62, rb loss = 3.663 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:36:34.518833: step 6140, G loss = 3.24, new loss = 14345.29, rb loss = 3.711 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:36:41.055952: step 6150, G loss = 3.40, new loss = 8716.24, rb loss = 3.991 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:36:47.663472: step 6160, G loss = 3.23, new loss = -12953.29, rb loss = 3.639 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 22:36:54.251565: step 6170, G loss = 3.30, new loss = 6065.93, rb loss = 3.902 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:37:00.878789: step 6180, G loss = 3.27, new loss = -418.85, rb loss = 3.692 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:37:07.377722: step 6190, G loss = 3.30, new loss = 9514.68, rb loss = 3.879 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:37:13.871779: step 6200, G loss = 3.29, new loss = -2538.20, rb loss = 3.673 (51.8 examples/sec; 0.618 sec/batch)
Evaluation at step 6200: loss 3.33546252251, rebalanced loss 3.77453569571.
2018-12-08 22:37:31.263831: step 6210, G loss = 3.26, new loss = 24608.43, rb loss = 4.032 (18.8 examples/sec; 1.705 sec/batch)
2018-12-08 22:37:37.765012: step 6220, G loss = 3.27, new loss = 14981.04, rb loss = 3.753 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:37:44.293553: step 6230, G loss = 3.42, new loss = 14168.39, rb loss = 4.037 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:37:50.850804: step 6240, G loss = 3.27, new loss = -11901.67, rb loss = 3.626 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:37:57.370586: step 6250, G loss = 3.40, new loss = -8546.73, rb loss = 3.849 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:38:03.926768: step 6260, G loss = 3.29, new loss = -22811.26, rb loss = 3.522 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:38:10.428976: step 6270, G loss = 3.36, new loss = 1503.06, rb loss = 3.894 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:38:16.939484: step 6280, G loss = 3.25, new loss = -18459.90, rb loss = 3.511 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:38:23.355926: step 6290, G loss = 3.25, new loss = -16633.54, rb loss = 3.492 (52.5 examples/sec; 0.609 sec/batch)
2018-12-08 22:38:29.854203: step 6300, G loss = 3.32, new loss = -10929.55, rb loss = 3.691 (51.7 examples/sec; 0.619 sec/batch)
Evaluation at step 6300: loss 3.33243492444, rebalanced loss 3.78315618038.
2018-12-08 22:38:47.418718: step 6310, G loss = 3.30, new loss = 17765.36, rb loss = 3.865 (18.6 examples/sec; 1.724 sec/batch)
2018-12-08 22:38:53.976592: step 6320, G loss = 3.32, new loss = -4452.71, rb loss = 3.710 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:39:00.463948: step 6330, G loss = 3.47, new loss = 50350.84, rb loss = 4.114 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 22:39:06.989929: step 6340, G loss = 3.12, new loss = -18693.44, rb loss = 3.417 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:39:13.480072: step 6350, G loss = 3.31, new loss = -3137.96, rb loss = 3.616 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:39:19.984176: step 6360, G loss = 3.40, new loss = -3205.82, rb loss = 3.750 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:39:26.559807: step 6370, G loss = 3.38, new loss = -2052.00, rb loss = 3.855 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:39:33.144107: step 6380, G loss = 3.37, new loss = 2667.28, rb loss = 3.797 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:39:39.699385: step 6390, G loss = 3.26, new loss = -11220.33, rb loss = 3.686 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:39:46.278003: step 6400, G loss = 3.41, new loss = -510.79, rb loss = 3.807 (51.2 examples/sec; 0.626 sec/batch)
Evaluation at step 6400: loss 3.3361067454, rebalanced loss 3.73922189077.
2018-12-08 22:40:03.903629: step 6410, G loss = 3.41, new loss = 4890.21, rb loss = 3.806 (18.5 examples/sec; 1.730 sec/batch)
2018-12-08 22:40:10.406394: step 6420, G loss = 3.30, new loss = -10340.57, rb loss = 3.561 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:40:16.903063: step 6430, G loss = 3.47, new loss = 40120.76, rb loss = 4.248 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:40:23.423396: step 6440, G loss = 3.31, new loss = -2405.16, rb loss = 3.715 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:40:29.937605: step 6450, G loss = 3.25, new loss = -22620.68, rb loss = 3.439 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:40:36.451475: step 6460, G loss = 3.39, new loss = 6944.03, rb loss = 3.793 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 22:40:42.985472: step 6470, G loss = 3.25, new loss = -8837.00, rb loss = 3.615 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:40:49.514668: step 6480, G loss = 3.19, new loss = -1233.27, rb loss = 3.610 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:40:56.050927: step 6490, G loss = 3.32, new loss = 27907.93, rb loss = 3.932 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:41:02.574094: step 6500, G loss = 3.35, new loss = 8644.98, rb loss = 3.837 (51.7 examples/sec; 0.620 sec/batch)
Evaluation at step 6500: loss 3.34292345047, rebalanced loss 3.78016645114.
2018-12-08 22:41:20.181617: step 6510, G loss = 3.41, new loss = -3112.91, rb loss = 3.795 (18.5 examples/sec; 1.727 sec/batch)
2018-12-08 22:41:26.752255: step 6520, G loss = 3.28, new loss = -11138.34, rb loss = 3.588 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:41:33.344563: step 6530, G loss = 3.16, new loss = -17593.35, rb loss = 3.424 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:41:39.940739: step 6540, G loss = 3.37, new loss = 8376.25, rb loss = 3.635 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:41:46.512850: step 6550, G loss = 3.42, new loss = 21322.98, rb loss = 4.033 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:41:53.085363: step 6560, G loss = 3.26, new loss = 83330.28, rb loss = 4.161 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:41:59.664649: step 6570, G loss = 3.34, new loss = -5471.85, rb loss = 3.790 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:42:06.248062: step 6580, G loss = 3.39, new loss = -10379.54, rb loss = 3.755 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:42:12.787446: step 6590, G loss = 3.44, new loss = 6128.96, rb loss = 3.815 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:42:19.260965: step 6600, G loss = 3.35, new loss = 29434.39, rb loss = 4.055 (52.1 examples/sec; 0.615 sec/batch)
Evaluation at step 6600: loss 3.34991480509, rebalanced loss 3.83419046402.
2018-12-08 22:42:37.196714: step 6610, G loss = 3.36, new loss = -8549.95, rb loss = 3.694 (18.2 examples/sec; 1.761 sec/batch)
2018-12-08 22:42:43.675684: step 6620, G loss = 3.35, new loss = -19739.91, rb loss = 3.590 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 22:42:50.217545: step 6630, G loss = 3.22, new loss = -14279.43, rb loss = 3.542 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:42:56.808014: step 6640, G loss = 3.31, new loss = -16153.30, rb loss = 3.559 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:43:03.352684: step 6650, G loss = 3.28, new loss = -1654.45, rb loss = 3.711 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 22:43:09.841621: step 6660, G loss = 3.32, new loss = -9600.01, rb loss = 3.737 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 22:43:16.361472: step 6670, G loss = 3.33, new loss = -9884.98, rb loss = 3.554 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:43:23.009525: step 6680, G loss = 3.41, new loss = 4382.37, rb loss = 3.856 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 22:43:29.488436: step 6690, G loss = 3.21, new loss = 7591.04, rb loss = 3.715 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 22:43:36.014159: step 6700, G loss = 3.28, new loss = -454.86, rb loss = 3.668 (51.6 examples/sec; 0.620 sec/batch)
Evaluation at step 6700: loss 3.32148968379, rebalanced loss 3.79057016373.
2018-12-08 22:43:53.631883: step 6710, G loss = 3.42, new loss = 28854.15, rb loss = 4.101 (18.5 examples/sec; 1.728 sec/batch)
2018-12-08 22:44:00.215001: step 6720, G loss = 3.33, new loss = 14762.42, rb loss = 3.886 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:44:06.771795: step 6730, G loss = 3.28, new loss = 3183.99, rb loss = 3.707 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:44:13.338753: step 6740, G loss = 3.47, new loss = 24867.10, rb loss = 4.049 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:44:19.917817: step 6750, G loss = 3.37, new loss = 2829.03, rb loss = 3.870 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:44:26.656353: step 6760, G loss = 3.25, new loss = -12067.94, rb loss = 3.579 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 22:44:33.340125: step 6770, G loss = 3.40, new loss = -20719.45, rb loss = 3.671 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 22:44:39.908904: step 6780, G loss = 3.17, new loss = -19411.93, rb loss = 3.500 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:44:46.465661: step 6790, G loss = 3.45, new loss = 8246.15, rb loss = 3.928 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:44:52.945248: step 6800, G loss = 3.34, new loss = -2222.22, rb loss = 3.701 (51.9 examples/sec; 0.616 sec/batch)
Evaluation at step 6800: loss 3.32928314209, rebalanced loss 3.83113369942.
2018-12-08 22:45:10.523505: step 6810, G loss = 3.27, new loss = -2889.72, rb loss = 3.740 (18.6 examples/sec; 1.725 sec/batch)
2018-12-08 22:45:17.099829: step 6820, G loss = 3.34, new loss = 2115.23, rb loss = 3.820 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:45:23.612755: step 6830, G loss = 3.29, new loss = 980.54, rb loss = 3.722 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 22:45:30.222110: step 6840, G loss = 3.31, new loss = -15373.83, rb loss = 3.392 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 22:45:36.836957: step 6850, G loss = 3.29, new loss = -17518.34, rb loss = 3.327 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:45:43.402681: step 6860, G loss = 3.30, new loss = 18248.90, rb loss = 3.969 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:45:49.962239: step 6870, G loss = 3.33, new loss = -8212.15, rb loss = 3.593 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:45:56.476397: step 6880, G loss = 3.35, new loss = -5799.78, rb loss = 3.632 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:46:03.189213: step 6890, G loss = 3.22, new loss = -16636.30, rb loss = 3.377 (50.1 examples/sec; 0.639 sec/batch)
2018-12-08 22:46:09.797587: step 6900, G loss = 3.38, new loss = -11929.22, rb loss = 3.679 (51.0 examples/sec; 0.628 sec/batch)
Evaluation at step 6900: loss 3.32024744352, rebalanced loss 3.73829957644.
2018-12-08 22:46:27.853179: step 6910, G loss = 3.24, new loss = -5935.23, rb loss = 3.557 (18.1 examples/sec; 1.773 sec/batch)
2018-12-08 22:46:34.466976: step 6920, G loss = 3.27, new loss = -4641.53, rb loss = 3.575 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:46:41.009408: step 6930, G loss = 3.30, new loss = -6434.98, rb loss = 3.530 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:46:47.476261: step 6940, G loss = 3.31, new loss = -1762.78, rb loss = 3.526 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 22:46:54.066062: step 6950, G loss = 3.27, new loss = 8801.68, rb loss = 3.677 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:47:00.637580: step 6960, G loss = 3.37, new loss = -21948.04, rb loss = 3.624 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:47:07.162329: step 6970, G loss = 3.33, new loss = -5837.71, rb loss = 3.679 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:47:13.672146: step 6980, G loss = 3.28, new loss = -16691.62, rb loss = 3.488 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 22:47:20.309596: step 6990, G loss = 3.23, new loss = -12029.49, rb loss = 3.561 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 22:47:26.909073: step 7000, G loss = 3.58, new loss = 49043.72, rb loss = 4.420 (51.0 examples/sec; 0.628 sec/batch)
Evaluation at step 7000: loss 3.37336742083, rebalanced loss 3.86700517337.
2018-12-08 22:47:49.450993: step 7010, G loss = 3.28, new loss = -6431.46, rb loss = 3.682 (14.4 examples/sec; 2.222 sec/batch)
2018-12-08 22:47:56.034053: step 7020, G loss = 3.24, new loss = -21880.65, rb loss = 3.487 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:48:02.580808: step 7030, G loss = 3.29, new loss = 5198.28, rb loss = 3.897 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:48:09.134474: step 7040, G loss = 3.30, new loss = -19639.84, rb loss = 3.380 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:48:15.701420: step 7050, G loss = 3.33, new loss = 1361.53, rb loss = 3.680 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:48:22.273009: step 7060, G loss = 3.27, new loss = 13247.74, rb loss = 3.881 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:48:28.848673: step 7070, G loss = 3.32, new loss = 1828.60, rb loss = 3.746 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:48:35.580397: step 7080, G loss = 3.37, new loss = 17738.92, rb loss = 4.012 (49.8 examples/sec; 0.642 sec/batch)
2018-12-08 22:48:42.153454: step 7090, G loss = 3.41, new loss = 11156.46, rb loss = 4.009 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:48:48.729661: step 7100, G loss = 3.46, new loss = 15597.62, rb loss = 3.861 (51.2 examples/sec; 0.625 sec/batch)
Evaluation at step 7100: loss 3.37242290179, rebalanced loss 3.8340164423.
2018-12-08 22:49:06.554560: step 7110, G loss = 3.41, new loss = 7349.87, rb loss = 3.894 (18.3 examples/sec; 1.750 sec/batch)
2018-12-08 22:49:13.196563: step 7120, G loss = 3.13, new loss = -23151.30, rb loss = 3.469 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:49:19.828558: step 7130, G loss = 3.18, new loss = -14708.17, rb loss = 3.454 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:49:26.432818: step 7140, G loss = 3.29, new loss = 1359.20, rb loss = 3.755 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:49:33.142472: step 7150, G loss = 3.28, new loss = -894.43, rb loss = 3.668 (50.2 examples/sec; 0.638 sec/batch)
2018-12-08 22:49:39.794108: step 7160, G loss = 3.32, new loss = 14424.54, rb loss = 3.806 (50.7 examples/sec; 0.632 sec/batch)
2018-12-08 22:49:46.344671: step 7170, G loss = 3.07, new loss = -8925.41, rb loss = 3.439 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:49:52.941422: step 7180, G loss = 3.30, new loss = -15902.10, rb loss = 3.655 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:49:59.487245: step 7190, G loss = 3.21, new loss = -16390.36, rb loss = 3.374 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:50:05.991440: step 7200, G loss = 3.34, new loss = 19394.15, rb loss = 4.172 (51.7 examples/sec; 0.618 sec/batch)
Evaluation at step 7200: loss 3.3394005696, rebalanced loss 3.77626160781.
2018-12-08 22:50:24.232289: step 7210, G loss = 3.32, new loss = 17829.31, rb loss = 3.992 (17.9 examples/sec; 1.791 sec/batch)
2018-12-08 22:50:30.792607: step 7220, G loss = 3.34, new loss = 4948.71, rb loss = 3.826 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:50:37.424782: step 7230, G loss = 3.32, new loss = -15608.16, rb loss = 3.601 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:50:44.005106: step 7240, G loss = 3.47, new loss = 1423.01, rb loss = 3.962 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:50:50.590264: step 7250, G loss = 3.48, new loss = 9789.38, rb loss = 3.894 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:50:57.172152: step 7260, G loss = 3.26, new loss = -20591.83, rb loss = 3.564 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:51:03.812611: step 7270, G loss = 3.39, new loss = 12578.87, rb loss = 3.727 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:51:10.383891: step 7280, G loss = 3.16, new loss = -10583.21, rb loss = 3.538 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:51:16.916419: step 7290, G loss = 3.24, new loss = -6735.96, rb loss = 3.515 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 22:51:23.469253: step 7300, G loss = 3.21, new loss = 1603.53, rb loss = 3.731 (51.4 examples/sec; 0.623 sec/batch)
Evaluation at step 7300: loss 3.32003707091, rebalanced loss 3.82513457934.
2018-12-08 22:51:41.600016: step 7310, G loss = 3.30, new loss = 4828.46, rb loss = 3.623 (18.0 examples/sec; 1.781 sec/batch)
2018-12-08 22:51:48.216038: step 7320, G loss = 3.20, new loss = -7401.29, rb loss = 3.593 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 22:51:54.792929: step 7330, G loss = 3.41, new loss = -10064.52, rb loss = 3.594 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:52:01.467425: step 7340, G loss = 3.24, new loss = -4778.08, rb loss = 3.673 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 22:52:08.067134: step 7350, G loss = 3.32, new loss = 6130.40, rb loss = 3.711 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:52:14.686727: step 7360, G loss = 3.26, new loss = -5829.23, rb loss = 3.589 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 22:52:21.272162: step 7370, G loss = 3.29, new loss = -19632.72, rb loss = 3.424 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:52:27.854384: step 7380, G loss = 3.51, new loss = 18268.10, rb loss = 3.975 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 22:52:34.463549: step 7390, G loss = 3.42, new loss = 54143.95, rb loss = 3.979 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 22:52:41.056164: step 7400, G loss = 3.29, new loss = -259.06, rb loss = 3.667 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 7400: loss 3.3492553393, rebalanced loss 3.76882529259.
2018-12-08 22:52:58.643183: step 7410, G loss = 3.35, new loss = -7408.45, rb loss = 3.806 (18.5 examples/sec; 1.727 sec/batch)
2018-12-08 22:53:05.233423: step 7420, G loss = 3.34, new loss = -10624.24, rb loss = 3.592 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:53:11.816407: step 7430, G loss = 3.34, new loss = -4800.28, rb loss = 3.688 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:53:18.462891: step 7440, G loss = 3.48, new loss = 3561.49, rb loss = 3.876 (50.7 examples/sec; 0.632 sec/batch)
2018-12-08 22:53:25.091947: step 7450, G loss = 3.36, new loss = -7822.73, rb loss = 3.737 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:53:31.716613: step 7460, G loss = 3.36, new loss = -4483.26, rb loss = 3.669 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:53:38.369618: step 7470, G loss = 3.53, new loss = 37288.26, rb loss = 4.300 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 22:53:45.024060: step 7480, G loss = 3.33, new loss = 6989.20, rb loss = 3.809 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 22:53:51.678574: step 7490, G loss = 3.22, new loss = -7021.70, rb loss = 3.678 (50.7 examples/sec; 0.632 sec/batch)
2018-12-08 22:53:58.342782: step 7500, G loss = 3.29, new loss = -20132.03, rb loss = 3.520 (50.6 examples/sec; 0.633 sec/batch)
Evaluation at step 7500: loss 3.33497947852, rebalanced loss 3.74869170189.
2018-12-08 22:54:16.125700: step 7510, G loss = 3.39, new loss = 3912.88, rb loss = 3.841 (18.3 examples/sec; 1.744 sec/batch)
2018-12-08 22:54:22.760558: step 7520, G loss = 3.29, new loss = -1854.27, rb loss = 3.642 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:54:29.322774: step 7530, G loss = 3.40, new loss = 34665.25, rb loss = 4.179 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:54:35.919694: step 7540, G loss = 3.21, new loss = -2653.80, rb loss = 3.644 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:54:42.500764: step 7550, G loss = 3.38, new loss = 23593.65, rb loss = 3.985 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:54:49.069072: step 7560, G loss = 3.31, new loss = 6671.18, rb loss = 3.749 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:54:55.660463: step 7570, G loss = 3.23, new loss = 4451.69, rb loss = 3.941 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:55:02.313157: step 7580, G loss = 3.29, new loss = 20922.17, rb loss = 3.893 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 22:55:08.879299: step 7590, G loss = 3.42, new loss = -1397.18, rb loss = 3.689 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 22:55:15.437520: step 7600, G loss = 3.40, new loss = 2406.55, rb loss = 3.884 (51.4 examples/sec; 0.623 sec/batch)
Evaluation at step 7600: loss 3.30776848793, rebalanced loss 3.68830804825.
2018-12-08 22:55:33.106566: step 7610, G loss = 3.29, new loss = 3315.24, rb loss = 3.650 (18.5 examples/sec; 1.734 sec/batch)
2018-12-08 22:55:39.688646: step 7620, G loss = 3.16, new loss = -10098.83, rb loss = 3.520 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 22:55:46.323056: step 7630, G loss = 3.30, new loss = 2023.55, rb loss = 3.721 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:55:52.982352: step 7640, G loss = 3.30, new loss = -1185.65, rb loss = 3.620 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 22:55:59.563109: step 7650, G loss = 3.27, new loss = 12006.70, rb loss = 3.976 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:56:06.192480: step 7660, G loss = 3.28, new loss = 38792.07, rb loss = 4.079 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 22:56:12.836642: step 7670, G loss = 3.45, new loss = 9484.72, rb loss = 4.105 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 22:56:19.723691: step 7680, G loss = 3.28, new loss = -13898.83, rb loss = 3.662 (48.8 examples/sec; 0.655 sec/batch)
2018-12-08 22:56:26.501991: step 7690, G loss = 3.22, new loss = 10271.84, rb loss = 3.720 (49.7 examples/sec; 0.644 sec/batch)
2018-12-08 22:56:33.125384: step 7700, G loss = 3.28, new loss = -930.54, rb loss = 3.774 (50.9 examples/sec; 0.629 sec/batch)
Evaluation at step 7700: loss 3.29938476086, rebalanced loss 3.70650762717.
2018-12-08 22:56:51.010645: step 7710, G loss = 3.29, new loss = 23954.72, rb loss = 4.077 (18.2 examples/sec; 1.756 sec/batch)
2018-12-08 22:56:57.598148: step 7720, G loss = 3.36, new loss = 1331.45, rb loss = 3.629 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 22:57:04.154830: step 7730, G loss = 3.30, new loss = 772.25, rb loss = 3.832 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:57:10.793579: step 7740, G loss = 3.31, new loss = -2719.52, rb loss = 3.685 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:57:17.394351: step 7750, G loss = 3.28, new loss = -10156.15, rb loss = 3.514 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:57:23.971337: step 7760, G loss = 3.50, new loss = 4151.50, rb loss = 3.933 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 22:57:30.542846: step 7770, G loss = 3.12, new loss = -3355.65, rb loss = 3.536 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:57:37.127921: step 7780, G loss = 3.30, new loss = 5665.30, rb loss = 3.759 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 22:57:43.832491: step 7790, G loss = 3.46, new loss = 34212.91, rb loss = 3.990 (50.3 examples/sec; 0.637 sec/batch)
2018-12-08 22:57:50.462383: step 7800, G loss = 3.28, new loss = -16948.48, rb loss = 3.330 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 7800: loss 3.33714721998, rebalanced loss 3.78531119823.
2018-12-08 22:58:08.419825: step 7810, G loss = 3.36, new loss = -7.88, rb loss = 3.808 (18.2 examples/sec; 1.763 sec/batch)
2018-12-08 22:58:15.178365: step 7820, G loss = 3.14, new loss = -4803.77, rb loss = 3.568 (49.8 examples/sec; 0.642 sec/batch)
2018-12-08 22:58:21.799691: step 7830, G loss = 3.35, new loss = 22286.57, rb loss = 4.046 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:58:28.431877: step 7840, G loss = 3.30, new loss = -16673.97, rb loss = 3.709 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 22:58:35.242708: step 7850, G loss = 3.23, new loss = -10588.18, rb loss = 3.333 (49.4 examples/sec; 0.647 sec/batch)
2018-12-08 22:58:41.846489: step 7860, G loss = 3.20, new loss = -19144.30, rb loss = 3.483 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 22:58:48.397344: step 7870, G loss = 3.33, new loss = -2218.38, rb loss = 3.709 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 22:58:55.080636: step 7880, G loss = 3.27, new loss = -15614.69, rb loss = 3.515 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 22:59:01.663363: step 7890, G loss = 3.21, new loss = 1901.81, rb loss = 3.529 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 22:59:08.273514: step 7900, G loss = 3.23, new loss = 10756.33, rb loss = 3.716 (50.9 examples/sec; 0.628 sec/batch)
Evaluation at step 7900: loss 3.34414952596, rebalanced loss 3.80093442599.
2018-12-08 22:59:26.260476: step 7910, G loss = 3.23, new loss = 19.00, rb loss = 3.653 (18.1 examples/sec; 1.767 sec/batch)
2018-12-08 22:59:32.992155: step 7920, G loss = 3.27, new loss = -12001.18, rb loss = 3.603 (50.0 examples/sec; 0.641 sec/batch)
2018-12-08 22:59:39.622214: step 7930, G loss = 3.36, new loss = 2513.46, rb loss = 3.772 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 22:59:46.214680: step 7940, G loss = 3.29, new loss = -9746.30, rb loss = 3.728 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 22:59:52.779288: step 7950, G loss = 3.29, new loss = -2386.76, rb loss = 3.542 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 22:59:59.364191: step 7960, G loss = 3.26, new loss = -20015.52, rb loss = 3.589 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:00:06.009079: step 7970, G loss = 3.36, new loss = 13231.86, rb loss = 3.981 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:00:12.602047: step 7980, G loss = 3.31, new loss = 16643.76, rb loss = 3.791 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:00:19.304862: step 7990, G loss = 3.25, new loss = -1318.18, rb loss = 3.597 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 23:00:25.884994: step 8000, G loss = 3.34, new loss = 13099.71, rb loss = 3.889 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 8000: loss 3.33190368811, rebalanced loss 3.7553438584.
2018-12-08 23:00:49.163542: step 8010, G loss = 3.34, new loss = -16394.59, rb loss = 3.532 (13.9 examples/sec; 2.295 sec/batch)
2018-12-08 23:00:55.760637: step 8020, G loss = 3.37, new loss = 10004.59, rb loss = 3.724 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:01:02.410318: step 8030, G loss = 3.43, new loss = 2505.29, rb loss = 3.813 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 23:01:09.000648: step 8040, G loss = 3.39, new loss = 12622.57, rb loss = 3.928 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:01:15.617706: step 8050, G loss = 3.24, new loss = -8107.96, rb loss = 3.513 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:01:22.189610: step 8060, G loss = 3.24, new loss = 8928.90, rb loss = 3.847 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:01:28.838451: step 8070, G loss = 3.35, new loss = -5418.95, rb loss = 3.657 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:01:35.463100: step 8080, G loss = 3.40, new loss = 16019.97, rb loss = 3.916 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 23:01:42.279102: step 8090, G loss = 3.38, new loss = -5756.72, rb loss = 3.759 (49.4 examples/sec; 0.648 sec/batch)
2018-12-08 23:01:48.976620: step 8100, G loss = 3.28, new loss = -7172.68, rb loss = 3.516 (50.2 examples/sec; 0.638 sec/batch)
Evaluation at step 8100: loss 3.36999051571, rebalanced loss 3.78974102338.
2018-12-08 23:02:06.714629: step 8110, G loss = 3.43, new loss = 22505.85, rb loss = 4.097 (18.4 examples/sec; 1.741 sec/batch)
2018-12-08 23:02:13.299451: step 8120, G loss = 3.35, new loss = 3159.35, rb loss = 3.841 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:02:19.926817: step 8130, G loss = 3.32, new loss = -6060.30, rb loss = 3.787 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 23:02:26.534466: step 8140, G loss = 3.24, new loss = -18520.77, rb loss = 3.596 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:02:33.092782: step 8150, G loss = 3.29, new loss = -21592.96, rb loss = 3.562 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:02:39.675270: step 8160, G loss = 3.34, new loss = 9281.40, rb loss = 3.760 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:02:46.297860: step 8170, G loss = 3.40, new loss = 5083.53, rb loss = 3.932 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:02:52.864829: step 8180, G loss = 3.43, new loss = 18870.83, rb loss = 4.028 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:02:59.458963: step 8190, G loss = 3.27, new loss = -14302.36, rb loss = 3.548 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:03:06.012845: step 8200, G loss = 3.25, new loss = 11458.91, rb loss = 3.715 (51.4 examples/sec; 0.622 sec/batch)
Evaluation at step 8200: loss 3.32583146095, rebalanced loss 3.71767163277.
2018-12-08 23:03:23.776434: step 8210, G loss = 3.36, new loss = 19550.28, rb loss = 4.102 (18.4 examples/sec; 1.743 sec/batch)
2018-12-08 23:03:30.386669: step 8220, G loss = 3.21, new loss = -10176.77, rb loss = 3.546 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:03:36.959689: step 8230, G loss = 3.29, new loss = -9425.52, rb loss = 3.521 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:03:43.531219: step 8240, G loss = 3.34, new loss = -2048.92, rb loss = 3.559 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:03:50.112533: step 8250, G loss = 3.30, new loss = -355.56, rb loss = 3.637 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:03:56.726161: step 8260, G loss = 3.42, new loss = -1670.21, rb loss = 3.780 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:04:03.305849: step 8270, G loss = 3.33, new loss = 9865.39, rb loss = 3.754 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:04:09.925760: step 8280, G loss = 3.39, new loss = 7317.05, rb loss = 3.990 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:04:16.522539: step 8290, G loss = 3.17, new loss = -25336.19, rb loss = 3.334 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:04:23.111220: step 8300, G loss = 3.27, new loss = -7994.90, rb loss = 3.702 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 8300: loss 3.37656632264, rebalanced loss 3.86903831164.
2018-12-08 23:04:41.131717: step 8310, G loss = 3.21, new loss = -9708.66, rb loss = 3.508 (18.1 examples/sec; 1.769 sec/batch)
2018-12-08 23:04:47.692625: step 8320, G loss = 3.26, new loss = -16753.76, rb loss = 3.470 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:04:54.210143: step 8330, G loss = 3.29, new loss = -11670.50, rb loss = 3.587 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:05:00.807171: step 8340, G loss = 3.42, new loss = -10702.98, rb loss = 3.823 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:05:07.362196: step 8350, G loss = 3.36, new loss = -9698.78, rb loss = 3.551 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:05:13.864106: step 8360, G loss = 3.31, new loss = 1561.13, rb loss = 3.632 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:05:20.434010: step 8370, G loss = 3.40, new loss = 20222.04, rb loss = 3.900 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:05:27.076640: step 8380, G loss = 3.21, new loss = -5911.00, rb loss = 3.506 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 23:05:33.748911: step 8390, G loss = 3.29, new loss = -9225.62, rb loss = 3.693 (50.5 examples/sec; 0.634 sec/batch)
2018-12-08 23:05:40.393233: step 8400, G loss = 3.30, new loss = -4091.04, rb loss = 3.641 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 8400: loss 3.33340087732, rebalanced loss 3.71743979454.
2018-12-08 23:05:58.099146: step 8410, G loss = 3.44, new loss = 28889.35, rb loss = 3.981 (18.4 examples/sec; 1.740 sec/batch)
2018-12-08 23:06:04.661005: step 8420, G loss = 3.36, new loss = 17932.31, rb loss = 3.823 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:06:11.291256: step 8430, G loss = 3.26, new loss = -16065.57, rb loss = 3.453 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:06:18.084984: step 8440, G loss = 3.41, new loss = -13600.64, rb loss = 3.683 (49.5 examples/sec; 0.647 sec/batch)
2018-12-08 23:06:24.667230: step 8450, G loss = 3.21, new loss = -24757.44, rb loss = 3.338 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:06:31.340389: step 8460, G loss = 3.15, new loss = -16228.44, rb loss = 3.246 (50.4 examples/sec; 0.634 sec/batch)
2018-12-08 23:06:37.954851: step 8470, G loss = 3.37, new loss = 13206.09, rb loss = 3.721 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:06:44.600414: step 8480, G loss = 3.32, new loss = -698.44, rb loss = 3.794 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 23:06:51.148521: step 8490, G loss = 3.36, new loss = 12984.44, rb loss = 3.963 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:06:57.798117: step 8500, G loss = 3.21, new loss = -12865.77, rb loss = 3.558 (50.7 examples/sec; 0.631 sec/batch)
Evaluation at step 8500: loss 3.36161875725, rebalanced loss 3.80770685673.
2018-12-08 23:07:15.634242: step 8510, G loss = 3.12, new loss = -8736.55, rb loss = 3.435 (18.3 examples/sec; 1.750 sec/batch)
2018-12-08 23:07:22.222268: step 8520, G loss = 3.40, new loss = -15254.00, rb loss = 3.392 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:07:28.756103: step 8530, G loss = 3.29, new loss = -71.56, rb loss = 3.700 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:07:35.294637: step 8540, G loss = 3.29, new loss = 2055.38, rb loss = 3.633 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:07:41.891451: step 8550, G loss = 3.34, new loss = 14852.82, rb loss = 3.694 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:07:48.508098: step 8560, G loss = 3.21, new loss = -18936.87, rb loss = 3.352 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:07:55.048547: step 8570, G loss = 3.33, new loss = -8943.66, rb loss = 3.606 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:08:01.537630: step 8580, G loss = 3.23, new loss = 1452.89, rb loss = 3.636 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:08:08.127556: step 8590, G loss = 3.34, new loss = 9662.09, rb loss = 3.915 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:08:14.674949: step 8600, G loss = 3.28, new loss = -14506.30, rb loss = 3.606 (51.5 examples/sec; 0.622 sec/batch)
Evaluation at step 8600: loss 3.35093721549, rebalanced loss 3.86253823439.
2018-12-08 23:08:32.374133: step 8610, G loss = 3.38, new loss = -1748.65, rb loss = 3.844 (18.4 examples/sec; 1.737 sec/batch)
2018-12-08 23:08:38.907364: step 8620, G loss = 3.25, new loss = 17940.98, rb loss = 3.870 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:08:45.455697: step 8630, G loss = 3.25, new loss = 4843.60, rb loss = 3.734 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:08:51.964016: step 8640, G loss = 3.28, new loss = -6816.07, rb loss = 3.725 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:08:58.399138: step 8650, G loss = 3.36, new loss = 7417.62, rb loss = 3.779 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 23:09:04.859802: step 8660, G loss = 3.22, new loss = -3504.68, rb loss = 3.575 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:09:11.331847: step 8670, G loss = 3.28, new loss = 8125.80, rb loss = 3.736 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:09:17.857195: step 8680, G loss = 3.30, new loss = 13623.68, rb loss = 3.853 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:09:24.317803: step 8690, G loss = 3.28, new loss = -19997.88, rb loss = 3.542 (52.1 examples/sec; 0.615 sec/batch)
2018-12-08 23:09:30.877009: step 8700, G loss = 3.34, new loss = -1382.21, rb loss = 3.687 (51.3 examples/sec; 0.624 sec/batch)
Evaluation at step 8700: loss 3.321946462, rebalanced loss 3.72471493085.
2018-12-08 23:09:48.559836: step 8710, G loss = 3.19, new loss = -11227.72, rb loss = 3.443 (18.4 examples/sec; 1.737 sec/batch)
2018-12-08 23:09:55.047337: step 8720, G loss = 3.17, new loss = -15509.21, rb loss = 3.446 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:10:01.687758: step 8730, G loss = 3.41, new loss = 8035.47, rb loss = 3.860 (50.7 examples/sec; 0.632 sec/batch)
2018-12-08 23:10:08.257123: step 8740, G loss = 3.37, new loss = -2700.72, rb loss = 3.747 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:10:14.740027: step 8750, G loss = 3.27, new loss = -5876.54, rb loss = 3.591 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 23:10:21.278078: step 8760, G loss = 3.18, new loss = -2495.55, rb loss = 3.540 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:10:27.792717: step 8770, G loss = 3.27, new loss = 11845.65, rb loss = 3.993 (51.7 examples/sec; 0.620 sec/batch)
2018-12-08 23:10:34.381913: step 8780, G loss = 3.26, new loss = -2233.80, rb loss = 3.546 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:10:40.930682: step 8790, G loss = 3.33, new loss = 36592.93, rb loss = 4.191 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:10:47.457023: step 8800, G loss = 3.14, new loss = -23209.31, rb loss = 3.350 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 8800: loss 3.32970007261, rebalanced loss 3.7351322492.
2018-12-08 23:11:05.220442: step 8810, G loss = 3.33, new loss = -8047.49, rb loss = 3.854 (18.3 examples/sec; 1.744 sec/batch)
2018-12-08 23:11:11.728541: step 8820, G loss = 3.31, new loss = -5550.28, rb loss = 3.647 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:11:18.291362: step 8830, G loss = 3.24, new loss = -23113.41, rb loss = 3.416 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:11:24.842715: step 8840, G loss = 3.25, new loss = -19850.50, rb loss = 3.585 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:11:31.299700: step 8850, G loss = 3.31, new loss = -16186.20, rb loss = 3.631 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:11:37.855275: step 8860, G loss = 3.37, new loss = 3832.64, rb loss = 3.754 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:11:44.272734: step 8870, G loss = 3.39, new loss = 16388.02, rb loss = 3.922 (52.4 examples/sec; 0.611 sec/batch)
2018-12-08 23:11:50.760185: step 8880, G loss = 3.25, new loss = -4816.69, rb loss = 3.522 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:11:57.316676: step 8890, G loss = 3.27, new loss = -6037.40, rb loss = 3.594 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:12:03.844644: step 8900, G loss = 3.22, new loss = -776.30, rb loss = 3.507 (51.6 examples/sec; 0.621 sec/batch)
Evaluation at step 8900: loss 3.31726827621, rebalanced loss 3.75452237129.
2018-12-08 23:12:21.552717: step 8910, G loss = 3.25, new loss = 12113.29, rb loss = 3.914 (18.4 examples/sec; 1.739 sec/batch)
2018-12-08 23:12:27.999431: step 8920, G loss = 3.47, new loss = 15195.07, rb loss = 3.955 (52.5 examples/sec; 0.610 sec/batch)
2018-12-08 23:12:34.521394: step 8930, G loss = 3.37, new loss = -5989.91, rb loss = 3.855 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:12:41.001476: step 8940, G loss = 3.33, new loss = -3939.52, rb loss = 3.932 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 23:12:47.471574: step 8950, G loss = 3.28, new loss = 12638.41, rb loss = 3.867 (52.1 examples/sec; 0.615 sec/batch)
2018-12-08 23:12:54.090987: step 8960, G loss = 3.32, new loss = -2172.28, rb loss = 3.667 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:13:00.487858: step 8970, G loss = 3.24, new loss = -23392.68, rb loss = 3.481 (52.5 examples/sec; 0.609 sec/batch)
2018-12-08 23:13:07.130919: step 8980, G loss = 3.23, new loss = -14387.38, rb loss = 3.470 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 23:13:13.692878: step 8990, G loss = 3.29, new loss = 17309.15, rb loss = 3.752 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 23:13:20.146629: step 9000, G loss = 3.41, new loss = -153.52, rb loss = 3.788 (52.2 examples/sec; 0.613 sec/batch)
Evaluation at step 9000: loss 3.32899816036, rebalanced loss 3.73220775127.
2018-12-08 23:13:42.464568: step 9010, G loss = 3.24, new loss = 2348.41, rb loss = 3.704 (14.6 examples/sec; 2.199 sec/batch)
2018-12-08 23:13:49.060298: step 9020, G loss = 3.37, new loss = -9236.03, rb loss = 3.603 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:13:55.732707: step 9030, G loss = 3.35, new loss = 3090.37, rb loss = 3.728 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 23:14:02.293405: step 9040, G loss = 3.21, new loss = -2481.60, rb loss = 3.536 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 23:14:08.751206: step 9050, G loss = 3.30, new loss = 33707.31, rb loss = 4.117 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:14:15.339665: step 9060, G loss = 3.24, new loss = 1181.05, rb loss = 3.738 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:14:22.075613: step 9070, G loss = 3.22, new loss = -4652.15, rb loss = 3.694 (50.0 examples/sec; 0.640 sec/batch)
2018-12-08 23:14:28.824688: step 9080, G loss = 3.31, new loss = 976.72, rb loss = 3.735 (49.9 examples/sec; 0.642 sec/batch)
2018-12-08 23:14:35.296650: step 9090, G loss = 3.21, new loss = -5962.69, rb loss = 3.752 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:14:41.825424: step 9100, G loss = 3.18, new loss = 4004.57, rb loss = 3.550 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 9100: loss 3.31443223159, rebalanced loss 3.76895332336.
2018-12-08 23:14:59.101395: step 9110, G loss = 3.28, new loss = -1576.15, rb loss = 3.643 (18.9 examples/sec; 1.696 sec/batch)
2018-12-08 23:15:05.534844: step 9120, G loss = 3.37, new loss = 32141.21, rb loss = 4.115 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:15:12.020613: step 9130, G loss = 3.38, new loss = 1179.67, rb loss = 3.724 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:15:18.608138: step 9140, G loss = 3.35, new loss = 28544.94, rb loss = 4.053 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:15:25.155875: step 9150, G loss = 3.31, new loss = 3062.05, rb loss = 3.704 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:15:31.713101: step 9160, G loss = 3.50, new loss = 37632.95, rb loss = 4.085 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:15:38.380122: step 9170, G loss = 3.28, new loss = -14309.68, rb loss = 3.588 (50.5 examples/sec; 0.634 sec/batch)
2018-12-08 23:15:44.858444: step 9180, G loss = 3.34, new loss = 2913.89, rb loss = 3.650 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 23:15:51.414012: step 9190, G loss = 3.10, new loss = -26487.32, rb loss = 3.288 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:15:57.924960: step 9200, G loss = 3.41, new loss = 25237.53, rb loss = 4.139 (51.7 examples/sec; 0.619 sec/batch)
Evaluation at step 9200: loss 3.33822278182, rebalanced loss 3.77408253352.
2018-12-08 23:16:15.417754: step 9210, G loss = 3.47, new loss = 31918.05, rb loss = 4.140 (18.6 examples/sec; 1.717 sec/batch)
2018-12-08 23:16:21.988826: step 9220, G loss = 3.17, new loss = -17116.19, rb loss = 3.438 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 23:16:28.483641: step 9230, G loss = 3.25, new loss = -6899.10, rb loss = 3.513 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:16:35.023243: step 9240, G loss = 3.31, new loss = 22858.96, rb loss = 3.893 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:16:41.520780: step 9250, G loss = 3.33, new loss = -17485.68, rb loss = 3.473 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:16:48.050766: step 9260, G loss = 3.12, new loss = -1006.88, rb loss = 3.548 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:16:54.594096: step 9270, G loss = 3.27, new loss = 6122.25, rb loss = 3.897 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:17:01.108509: step 9280, G loss = 3.38, new loss = -2627.01, rb loss = 3.669 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:17:07.691002: step 9290, G loss = 3.27, new loss = -11854.53, rb loss = 3.672 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:17:14.299790: step 9300, G loss = 3.37, new loss = 29406.10, rb loss = 4.010 (50.9 examples/sec; 0.629 sec/batch)
Evaluation at step 9300: loss 3.32262726625, rebalanced loss 3.71129066149.
2018-12-08 23:17:32.260912: step 9310, G loss = 3.41, new loss = 12738.02, rb loss = 3.853 (18.1 examples/sec; 1.765 sec/batch)
2018-12-08 23:17:38.848939: step 9320, G loss = 3.32, new loss = 2596.58, rb loss = 3.634 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:17:45.353410: step 9330, G loss = 3.32, new loss = 608.46, rb loss = 3.637 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:17:51.936323: step 9340, G loss = 3.35, new loss = -2021.77, rb loss = 3.794 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:17:58.499947: step 9350, G loss = 3.26, new loss = -4609.23, rb loss = 3.544 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:18:05.085137: step 9360, G loss = 3.21, new loss = -9521.87, rb loss = 3.581 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:18:11.564090: step 9370, G loss = 3.21, new loss = -1212.02, rb loss = 3.595 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:18:18.068850: step 9380, G loss = 3.26, new loss = -8193.29, rb loss = 3.503 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:18:24.642595: step 9390, G loss = 3.35, new loss = 15813.52, rb loss = 3.925 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:18:31.335165: step 9400, G loss = 3.33, new loss = -9065.86, rb loss = 3.792 (50.4 examples/sec; 0.635 sec/batch)
Evaluation at step 9400: loss 3.33149091403, rebalanced loss 3.78315869172.
2018-12-08 23:18:49.346251: step 9410, G loss = 3.41, new loss = 4533.70, rb loss = 3.897 (18.1 examples/sec; 1.769 sec/batch)
2018-12-08 23:18:55.902880: step 9420, G loss = 3.22, new loss = -8797.65, rb loss = 3.446 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:19:02.560046: step 9430, G loss = 3.29, new loss = -3499.89, rb loss = 3.674 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 23:19:09.122385: step 9440, G loss = 3.39, new loss = -10427.74, rb loss = 3.595 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:19:15.813463: step 9450, G loss = 3.34, new loss = -5333.91, rb loss = 3.641 (50.2 examples/sec; 0.638 sec/batch)
2018-12-08 23:19:22.274331: step 9460, G loss = 3.35, new loss = -7901.41, rb loss = 3.674 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 23:19:28.802877: step 9470, G loss = 3.27, new loss = -8458.33, rb loss = 3.680 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 23:19:35.324033: step 9480, G loss = 3.24, new loss = -9077.90, rb loss = 3.573 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:19:41.839680: step 9490, G loss = 3.36, new loss = -6845.05, rb loss = 3.647 (51.7 examples/sec; 0.620 sec/batch)
2018-12-08 23:19:48.509044: step 9500, G loss = 3.16, new loss = -13457.89, rb loss = 3.440 (50.5 examples/sec; 0.634 sec/batch)
Evaluation at step 9500: loss 3.35349171956, rebalanced loss 3.79128237565.
2018-12-08 23:20:06.442121: step 9510, G loss = 3.43, new loss = 36242.00, rb loss = 4.063 (18.2 examples/sec; 1.762 sec/batch)
2018-12-08 23:20:12.921073: step 9520, G loss = 3.33, new loss = -2541.98, rb loss = 3.688 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:20:19.349119: step 9530, G loss = 3.41, new loss = -16105.19, rb loss = 3.631 (52.4 examples/sec; 0.611 sec/batch)
2018-12-08 23:20:25.950674: step 9540, G loss = 3.33, new loss = -3998.68, rb loss = 3.720 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:20:32.486758: step 9550, G loss = 3.30, new loss = 504.80, rb loss = 3.750 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:20:38.940157: step 9560, G loss = 3.34, new loss = 4146.75, rb loss = 3.720 (52.0 examples/sec; 0.616 sec/batch)
2018-12-08 23:20:45.515156: step 9570, G loss = 3.44, new loss = 12402.49, rb loss = 4.099 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:20:52.054057: step 9580, G loss = 3.16, new loss = -26529.82, rb loss = 3.353 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:20:58.538591: step 9590, G loss = 3.35, new loss = 1549.65, rb loss = 3.807 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:21:05.086552: step 9600, G loss = 3.39, new loss = 31215.25, rb loss = 4.129 (51.5 examples/sec; 0.622 sec/batch)
Evaluation at step 9600: loss 3.3359013478, rebalanced loss 3.73696757952.
2018-12-08 23:21:22.432953: step 9610, G loss = 3.20, new loss = -14159.18, rb loss = 3.521 (18.8 examples/sec; 1.701 sec/batch)
2018-12-08 23:21:28.961527: step 9620, G loss = 3.24, new loss = -13834.60, rb loss = 3.648 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:21:35.550116: step 9630, G loss = 3.26, new loss = -6452.60, rb loss = 3.752 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:21:42.357804: step 9640, G loss = 3.21, new loss = 3217.61, rb loss = 3.680 (49.4 examples/sec; 0.648 sec/batch)
2018-12-08 23:21:48.834157: step 9650, G loss = 3.43, new loss = -14708.46, rb loss = 3.724 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:21:55.486948: step 9660, G loss = 3.29, new loss = -2699.27, rb loss = 3.790 (50.5 examples/sec; 0.633 sec/batch)
2018-12-08 23:22:01.947656: step 9670, G loss = 3.40, new loss = 20672.15, rb loss = 4.059 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:22:08.428347: step 9680, G loss = 3.44, new loss = -6186.02, rb loss = 3.853 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:22:14.953581: step 9690, G loss = 3.30, new loss = -4684.54, rb loss = 3.638 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 23:22:21.477515: step 9700, G loss = 3.20, new loss = -16597.79, rb loss = 3.430 (51.6 examples/sec; 0.620 sec/batch)
Evaluation at step 9700: loss 3.35728391806, rebalanced loss 3.79093491236.
2018-12-08 23:22:38.983590: step 9710, G loss = 3.51, new loss = 31225.48, rb loss = 4.030 (18.6 examples/sec; 1.719 sec/batch)
2018-12-08 23:22:45.408236: step 9720, G loss = 3.45, new loss = 21558.86, rb loss = 4.193 (52.4 examples/sec; 0.611 sec/batch)
2018-12-08 23:22:51.962591: step 9730, G loss = 3.29, new loss = 9262.26, rb loss = 3.788 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:22:58.441614: step 9740, G loss = 3.32, new loss = 8360.72, rb loss = 3.762 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:23:04.907315: step 9750, G loss = 3.23, new loss = -739.16, rb loss = 3.544 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:23:11.571182: step 9760, G loss = 3.27, new loss = -15964.40, rb loss = 3.469 (50.5 examples/sec; 0.634 sec/batch)
2018-12-08 23:23:18.185801: step 9770, G loss = 3.33, new loss = 3578.30, rb loss = 3.765 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:23:24.805948: step 9780, G loss = 3.32, new loss = 6030.61, rb loss = 3.802 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:23:31.347404: step 9790, G loss = 3.18, new loss = -11727.68, rb loss = 3.615 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 23:23:37.912438: step 9800, G loss = 3.36, new loss = -5090.24, rb loss = 3.831 (51.2 examples/sec; 0.625 sec/batch)
Evaluation at step 9800: loss 3.35700180531, rebalanced loss 3.74168953101.
2018-12-08 23:23:55.127294: step 9810, G loss = 3.17, new loss = -21258.40, rb loss = 3.269 (18.9 examples/sec; 1.689 sec/batch)
2018-12-08 23:24:01.603613: step 9820, G loss = 3.21, new loss = -10325.60, rb loss = 3.461 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:24:08.209247: step 9830, G loss = 3.46, new loss = 149.70, rb loss = 3.784 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 23:24:14.666802: step 9840, G loss = 3.22, new loss = 11846.56, rb loss = 3.855 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:24:21.130380: step 9850, G loss = 3.23, new loss = -469.78, rb loss = 3.583 (52.1 examples/sec; 0.615 sec/batch)
2018-12-08 23:24:27.647440: step 9860, G loss = 3.25, new loss = -16930.41, rb loss = 3.508 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:24:34.210909: step 9870, G loss = 3.29, new loss = 1936.84, rb loss = 3.690 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:24:40.743330: step 9880, G loss = 3.46, new loss = 38608.39, rb loss = 4.088 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:24:47.256262: step 9890, G loss = 3.33, new loss = -5897.34, rb loss = 3.819 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:24:53.729857: step 9900, G loss = 3.16, new loss = -12423.48, rb loss = 3.363 (52.0 examples/sec; 0.615 sec/batch)
Evaluation at step 9900: loss 3.30683053335, rebalanced loss 3.67186618646.
2018-12-08 23:25:11.650338: step 9910, G loss = 3.23, new loss = -13210.26, rb loss = 3.578 (18.2 examples/sec; 1.762 sec/batch)
2018-12-08 23:25:18.104273: step 9920, G loss = 3.30, new loss = -11881.60, rb loss = 3.540 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 23:25:24.608382: step 9930, G loss = 3.27, new loss = -8327.09, rb loss = 3.571 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:25:31.153563: step 9940, G loss = 3.24, new loss = -5447.10, rb loss = 3.536 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:25:37.714111: step 9950, G loss = 3.35, new loss = -14620.48, rb loss = 3.608 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:25:44.311042: step 9960, G loss = 3.32, new loss = -14494.12, rb loss = 3.578 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:25:50.779410: step 9970, G loss = 3.34, new loss = -6405.50, rb loss = 3.757 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:25:57.265423: step 9980, G loss = 3.44, new loss = 4178.22, rb loss = 3.947 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:26:03.799182: step 9990, G loss = 3.30, new loss = -10285.48, rb loss = 3.679 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:26:10.375878: step 10000, G loss = 3.26, new loss = -2685.41, rb loss = 3.559 (51.3 examples/sec; 0.624 sec/batch)
Evaluation at step 10000: loss 3.37226545016, rebalanced loss 3.81180383364.
2018-12-08 23:28:44.465620: step 10010, G loss = 3.24, new loss = -11071.73, rb loss = 3.451 (2.1 examples/sec; 15.376 sec/batch)
2018-12-08 23:28:50.954662: step 10020, G loss = 3.31, new loss = -13466.01, rb loss = 3.635 (51.9 examples/sec; 0.617 sec/batch)
2018-12-08 23:28:57.420457: step 10030, G loss = 3.26, new loss = 9904.26, rb loss = 3.736 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:29:03.906743: step 10040, G loss = 3.37, new loss = -7428.62, rb loss = 3.563 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 23:29:10.374141: step 10050, G loss = 3.20, new loss = -16693.96, rb loss = 3.423 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:29:16.887486: step 10060, G loss = 3.25, new loss = -17460.94, rb loss = 3.381 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:29:23.490183: step 10070, G loss = 3.28, new loss = -15885.78, rb loss = 3.417 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:29:30.075069: step 10080, G loss = 3.21, new loss = -4452.12, rb loss = 3.577 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:29:36.536722: step 10090, G loss = 3.35, new loss = -74.27, rb loss = 3.637 (52.1 examples/sec; 0.614 sec/batch)
2018-12-08 23:29:43.035396: step 10100, G loss = 3.36, new loss = 5909.68, rb loss = 3.634 (51.8 examples/sec; 0.618 sec/batch)
Evaluation at step 10100: loss 3.33842253685, rebalanced loss 3.80642806689.
2018-12-08 23:30:00.883837: step 10110, G loss = 3.32, new loss = 18254.38, rb loss = 3.878 (18.3 examples/sec; 1.753 sec/batch)
2018-12-08 23:30:07.369178: step 10120, G loss = 3.35, new loss = 14702.57, rb loss = 4.008 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:30:13.824836: step 10130, G loss = 3.36, new loss = -10158.59, rb loss = 3.609 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 23:30:20.275122: step 10140, G loss = 3.47, new loss = -11118.72, rb loss = 3.680 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 23:30:26.730327: step 10150, G loss = 3.39, new loss = 11736.68, rb loss = 3.892 (52.2 examples/sec; 0.613 sec/batch)
2018-12-08 23:30:33.227655: step 10160, G loss = 3.40, new loss = -15404.06, rb loss = 3.783 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:30:39.728440: step 10170, G loss = 3.41, new loss = 20142.50, rb loss = 3.956 (51.7 examples/sec; 0.618 sec/batch)
2018-12-08 23:30:46.308267: step 10180, G loss = 3.43, new loss = -6375.41, rb loss = 3.815 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:30:52.869929: step 10190, G loss = 3.30, new loss = -23801.12, rb loss = 3.356 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:30:59.415566: step 10200, G loss = 3.16, new loss = -1967.18, rb loss = 3.626 (51.5 examples/sec; 0.622 sec/batch)
Evaluation at step 10200: loss 3.35345977942, rebalanced loss 3.81857581139.
2018-12-08 23:31:17.123190: step 10210, G loss = 3.29, new loss = -506.05, rb loss = 3.798 (18.4 examples/sec; 1.739 sec/batch)
2018-12-08 23:31:23.563925: step 10220, G loss = 3.27, new loss = 2501.70, rb loss = 3.729 (52.4 examples/sec; 0.611 sec/batch)
2018-12-08 23:31:30.057902: step 10230, G loss = 3.28, new loss = -23323.84, rb loss = 3.438 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:31:36.558081: step 10240, G loss = 3.23, new loss = -6275.04, rb loss = 3.396 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:31:43.145885: step 10250, G loss = 3.24, new loss = -2270.78, rb loss = 3.610 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:31:49.687681: step 10260, G loss = 3.24, new loss = -22887.17, rb loss = 3.356 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:31:56.117414: step 10270, G loss = 3.35, new loss = -13837.48, rb loss = 3.644 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 23:32:02.769770: step 10280, G loss = 3.19, new loss = -8825.49, rb loss = 3.568 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 23:32:09.287464: step 10290, G loss = 3.12, new loss = -19190.18, rb loss = 3.432 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:32:15.812769: step 10300, G loss = 3.38, new loss = 24155.66, rb loss = 4.036 (51.6 examples/sec; 0.620 sec/batch)
Evaluation at step 10300: loss 3.33072117964, rebalanced loss 3.76435674032.
2018-12-08 23:32:33.506263: step 10310, G loss = 3.36, new loss = 13061.61, rb loss = 4.021 (18.4 examples/sec; 1.738 sec/batch)
2018-12-08 23:32:40.122605: step 10320, G loss = 3.56, new loss = 29617.91, rb loss = 3.947 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:32:46.701054: step 10330, G loss = 3.28, new loss = 16643.25, rb loss = 3.877 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 23:32:53.259616: step 10340, G loss = 3.29, new loss = -6826.13, rb loss = 3.636 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:32:59.740615: step 10350, G loss = 3.25, new loss = -8719.63, rb loss = 3.291 (51.9 examples/sec; 0.616 sec/batch)
2018-12-08 23:33:06.176744: step 10360, G loss = 3.28, new loss = -19869.49, rb loss = 3.567 (52.3 examples/sec; 0.612 sec/batch)
2018-12-08 23:33:12.675673: step 10370, G loss = 3.34, new loss = -10569.18, rb loss = 3.617 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:33:19.180960: step 10380, G loss = 3.20, new loss = -4278.48, rb loss = 3.632 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:33:25.659237: step 10390, G loss = 3.23, new loss = -12961.19, rb loss = 3.437 (52.0 examples/sec; 0.615 sec/batch)
2018-12-08 23:33:32.110631: step 10400, G loss = 3.39, new loss = 15586.95, rb loss = 4.080 (52.2 examples/sec; 0.613 sec/batch)
Evaluation at step 10400: loss 3.2955529213, rebalanced loss 3.72436608473.
2018-12-08 23:33:49.422362: step 10410, G loss = 3.32, new loss = 26523.18, rb loss = 4.071 (18.8 examples/sec; 1.700 sec/batch)
2018-12-08 23:33:55.975242: step 10420, G loss = 3.22, new loss = -17970.80, rb loss = 3.454 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:34:02.496860: step 10430, G loss = 3.40, new loss = 951.15, rb loss = 3.711 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:34:09.031238: step 10440, G loss = 3.23, new loss = -10747.84, rb loss = 3.666 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:34:15.592654: step 10450, G loss = 3.33, new loss = -11523.15, rb loss = 3.471 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 23:34:22.154302: step 10460, G loss = 3.31, new loss = -4252.66, rb loss = 3.568 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:34:28.636235: step 10470, G loss = 3.32, new loss = -833.15, rb loss = 3.602 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:34:35.129508: step 10480, G loss = 3.25, new loss = -10859.61, rb loss = 3.575 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:34:41.684904: step 10490, G loss = 3.33, new loss = -5150.20, rb loss = 3.627 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:34:48.193619: step 10500, G loss = 3.25, new loss = -14201.50, rb loss = 3.702 (51.8 examples/sec; 0.617 sec/batch)
Evaluation at step 10500: loss 3.34095590909, rebalanced loss 3.87899353504.
2018-12-08 23:35:05.734656: step 10510, G loss = 3.18, new loss = 836.08, rb loss = 3.522 (18.6 examples/sec; 1.722 sec/batch)
2018-12-08 23:35:12.312005: step 10520, G loss = 3.21, new loss = -14991.00, rb loss = 3.505 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:35:18.845631: step 10530, G loss = 3.35, new loss = 20912.48, rb loss = 3.913 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 23:35:25.444854: step 10540, G loss = 3.36, new loss = 9932.80, rb loss = 3.827 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:35:32.002951: step 10550, G loss = 3.24, new loss = -20938.01, rb loss = 3.441 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:35:38.595854: step 10560, G loss = 3.38, new loss = 20688.36, rb loss = 3.937 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:35:45.210671: step 10570, G loss = 3.25, new loss = -10071.02, rb loss = 3.556 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:35:51.740886: step 10580, G loss = 3.26, new loss = -2857.83, rb loss = 3.602 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:35:58.331106: step 10590, G loss = 3.45, new loss = 10611.65, rb loss = 3.996 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:36:04.934091: step 10600, G loss = 3.26, new loss = 2770.03, rb loss = 3.681 (50.9 examples/sec; 0.629 sec/batch)
Evaluation at step 10600: loss 3.34817548593, rebalanced loss 3.73632957935.
2018-12-08 23:36:22.707531: step 10610, G loss = 3.21, new loss = -17124.17, rb loss = 3.451 (18.3 examples/sec; 1.745 sec/batch)
2018-12-08 23:36:29.252987: step 10620, G loss = 3.27, new loss = 18347.04, rb loss = 3.697 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:36:35.854330: step 10630, G loss = 3.32, new loss = 3140.24, rb loss = 3.738 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:36:42.531767: step 10640, G loss = 3.33, new loss = -1114.22, rb loss = 3.829 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 23:36:49.148641: step 10650, G loss = 3.34, new loss = 52412.07, rb loss = 4.250 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:36:55.774821: step 10660, G loss = 3.42, new loss = -2494.68, rb loss = 3.833 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:37:02.338179: step 10670, G loss = 3.53, new loss = 7277.15, rb loss = 3.968 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:37:08.953010: step 10680, G loss = 3.26, new loss = 21437.81, rb loss = 3.739 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:37:15.474239: step 10690, G loss = 3.42, new loss = -1492.43, rb loss = 3.932 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 23:37:21.902285: step 10700, G loss = 3.34, new loss = 10199.92, rb loss = 3.703 (52.4 examples/sec; 0.611 sec/batch)
Evaluation at step 10700: loss 3.35867607594, rebalanced loss 3.81674369176.
2018-12-08 23:37:39.567770: step 10710, G loss = 3.26, new loss = -18119.40, rb loss = 3.558 (18.5 examples/sec; 1.733 sec/batch)
2018-12-08 23:37:46.292217: step 10720, G loss = 3.23, new loss = -24903.26, rb loss = 3.457 (50.1 examples/sec; 0.639 sec/batch)
2018-12-08 23:37:52.936888: step 10730, G loss = 3.27, new loss = 8535.62, rb loss = 3.775 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:37:59.569050: step 10740, G loss = 3.31, new loss = 8055.35, rb loss = 3.801 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:38:06.163898: step 10750, G loss = 3.31, new loss = -5513.15, rb loss = 3.362 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:38:12.781730: step 10760, G loss = 3.28, new loss = 9264.03, rb loss = 3.719 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:38:19.377249: step 10770, G loss = 3.35, new loss = -11696.42, rb loss = 3.571 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:38:25.925962: step 10780, G loss = 3.40, new loss = -6572.75, rb loss = 3.689 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:38:32.515895: step 10790, G loss = 3.35, new loss = -7279.36, rb loss = 3.716 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:38:39.219791: step 10800, G loss = 3.25, new loss = 11847.74, rb loss = 3.851 (50.3 examples/sec; 0.637 sec/batch)
Evaluation at step 10800: loss 3.32454787095, rebalanced loss 3.76331519286.
2018-12-08 23:38:57.155440: step 10810, G loss = 3.24, new loss = -12241.21, rb loss = 3.566 (18.2 examples/sec; 1.760 sec/batch)
2018-12-08 23:39:03.781774: step 10820, G loss = 3.19, new loss = -3315.44, rb loss = 3.654 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 23:39:10.639180: step 10830, G loss = 3.16, new loss = -13717.62, rb loss = 3.261 (49.0 examples/sec; 0.653 sec/batch)
2018-12-08 23:39:17.271196: step 10840, G loss = 3.20, new loss = -3230.90, rb loss = 3.322 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:39:23.803495: step 10850, G loss = 3.31, new loss = -2963.84, rb loss = 3.627 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:39:30.387559: step 10860, G loss = 3.28, new loss = 4727.47, rb loss = 3.690 (51.2 examples/sec; 0.624 sec/batch)
2018-12-08 23:39:37.020534: step 10870, G loss = 3.33, new loss = -4713.58, rb loss = 3.674 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:39:43.618115: step 10880, G loss = 3.39, new loss = 3318.93, rb loss = 3.742 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:39:50.319310: step 10890, G loss = 3.36, new loss = 16865.05, rb loss = 3.937 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 23:39:56.900183: step 10900, G loss = 3.42, new loss = 1021.31, rb loss = 3.756 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 10900: loss 3.34130797386, rebalanced loss 3.80016067028.
2018-12-08 23:40:14.998457: step 10910, G loss = 3.27, new loss = -15275.86, rb loss = 3.416 (18.0 examples/sec; 1.778 sec/batch)
2018-12-08 23:40:21.701957: step 10920, G loss = 3.38, new loss = 29255.14, rb loss = 4.060 (50.2 examples/sec; 0.638 sec/batch)
2018-12-08 23:40:28.271565: step 10930, G loss = 3.20, new loss = -10079.15, rb loss = 3.551 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:40:34.927417: step 10940, G loss = 3.37, new loss = 22800.80, rb loss = 4.063 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:40:41.491204: step 10950, G loss = 3.27, new loss = -15172.66, rb loss = 3.436 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:40:48.034291: step 10960, G loss = 3.25, new loss = -4545.53, rb loss = 3.666 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:40:54.648817: step 10970, G loss = 3.32, new loss = -18294.67, rb loss = 3.373 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:41:01.296506: step 10980, G loss = 3.21, new loss = 3646.79, rb loss = 3.694 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 23:41:07.918604: step 10990, G loss = 3.45, new loss = 19563.91, rb loss = 3.965 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 23:41:14.519208: step 11000, G loss = 3.23, new loss = -9680.65, rb loss = 3.345 (50.9 examples/sec; 0.628 sec/batch)
Evaluation at step 11000: loss 3.32058668931, rebalanced loss 3.75864344438.
2018-12-08 23:41:38.167607: step 11010, G loss = 3.34, new loss = 16872.77, rb loss = 3.865 (13.7 examples/sec; 2.333 sec/batch)
2018-12-08 23:41:44.711816: step 11020, G loss = 3.35, new loss = -2929.37, rb loss = 3.883 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:41:51.387696: step 11030, G loss = 3.27, new loss = 4067.90, rb loss = 3.714 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 23:41:57.958168: step 11040, G loss = 3.56, new loss = 56754.06, rb loss = 4.447 (51.6 examples/sec; 0.620 sec/batch)
2018-12-08 23:42:04.569035: step 11050, G loss = 3.32, new loss = 18241.68, rb loss = 3.739 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:42:11.139728: step 11060, G loss = 3.22, new loss = -12214.46, rb loss = 3.692 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:42:17.700868: step 11070, G loss = 3.14, new loss = -25485.75, rb loss = 3.425 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:42:24.330764: step 11080, G loss = 3.28, new loss = 3642.76, rb loss = 3.633 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:42:30.886790: step 11090, G loss = 3.25, new loss = -11311.69, rb loss = 3.638 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:42:37.442619: step 11100, G loss = 3.38, new loss = 5410.27, rb loss = 3.797 (51.2 examples/sec; 0.624 sec/batch)
Evaluation at step 11100: loss 3.34850282669, rebalanced loss 3.83420260747.
2018-12-08 23:42:55.287018: step 11110, G loss = 3.21, new loss = -9684.52, rb loss = 3.343 (18.3 examples/sec; 1.752 sec/batch)
2018-12-08 23:43:01.982944: step 11120, G loss = 3.29, new loss = -1909.88, rb loss = 3.760 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 23:43:08.619256: step 11130, G loss = 3.26, new loss = 1082.05, rb loss = 3.740 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:43:15.224559: step 11140, G loss = 3.31, new loss = -9905.25, rb loss = 3.682 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:43:21.831395: step 11150, G loss = 3.30, new loss = 16143.08, rb loss = 3.940 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:43:28.416447: step 11160, G loss = 3.28, new loss = -11177.57, rb loss = 3.555 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:43:34.943396: step 11170, G loss = 3.37, new loss = 18554.89, rb loss = 3.943 (51.8 examples/sec; 0.618 sec/batch)
2018-12-08 23:43:41.537453: step 11180, G loss = 3.33, new loss = 2131.26, rb loss = 3.656 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:43:48.112942: step 11190, G loss = 3.36, new loss = 8921.23, rb loss = 3.949 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 23:43:54.719396: step 11200, G loss = 3.36, new loss = 5071.15, rb loss = 3.829 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 11200: loss 3.30980506738, rebalanced loss 3.76818410556.
2018-12-08 23:44:12.432395: step 11210, G loss = 3.46, new loss = -5536.81, rb loss = 3.728 (18.4 examples/sec; 1.739 sec/batch)
2018-12-08 23:44:18.993153: step 11220, G loss = 3.29, new loss = 25229.71, rb loss = 3.844 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:44:25.580583: step 11230, G loss = 3.18, new loss = -9508.39, rb loss = 3.516 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:44:32.213322: step 11240, G loss = 3.37, new loss = -6505.14, rb loss = 3.718 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:44:38.817834: step 11250, G loss = 3.16, new loss = -11842.67, rb loss = 3.508 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:44:45.397185: step 11260, G loss = 3.28, new loss = -19731.26, rb loss = 3.548 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:44:52.044083: step 11270, G loss = 3.44, new loss = 5419.45, rb loss = 3.739 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:44:58.747749: step 11280, G loss = 3.28, new loss = -3033.80, rb loss = 3.596 (50.2 examples/sec; 0.638 sec/batch)
2018-12-08 23:45:05.446045: step 11290, G loss = 3.41, new loss = -858.94, rb loss = 3.834 (50.2 examples/sec; 0.637 sec/batch)
2018-12-08 23:45:12.059782: step 11300, G loss = 3.27, new loss = -3702.75, rb loss = 3.622 (50.9 examples/sec; 0.628 sec/batch)
Evaluation at step 11300: loss 3.36551380157, rebalanced loss 3.79226885637.
2018-12-08 23:45:30.465807: step 11310, G loss = 3.31, new loss = 13353.57, rb loss = 3.901 (17.7 examples/sec; 1.808 sec/batch)
2018-12-08 23:45:37.082303: step 11320, G loss = 3.17, new loss = -13291.85, rb loss = 3.660 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:45:43.687305: step 11330, G loss = 3.27, new loss = -22159.77, rb loss = 3.545 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:45:50.305508: step 11340, G loss = 3.37, new loss = 58649.73, rb loss = 4.346 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:45:56.943575: step 11350, G loss = 3.40, new loss = 20284.71, rb loss = 3.796 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:46:03.585531: step 11360, G loss = 3.38, new loss = 18032.04, rb loss = 4.054 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:46:10.119836: step 11370, G loss = 3.37, new loss = -9037.56, rb loss = 3.843 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:46:16.684768: step 11380, G loss = 3.16, new loss = -25300.54, rb loss = 3.292 (51.3 examples/sec; 0.623 sec/batch)
2018-12-08 23:46:23.251671: step 11390, G loss = 3.22, new loss = -10076.75, rb loss = 3.389 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:46:30.427494: step 11400, G loss = 3.14, new loss = -15970.42, rb loss = 3.332 (46.9 examples/sec; 0.682 sec/batch)
Evaluation at step 11400: loss 3.32740613619, rebalanced loss 3.74372983774.
2018-12-08 23:46:56.832313: step 11410, G loss = 3.38, new loss = 4443.85, rb loss = 3.894 (12.5 examples/sec; 2.561 sec/batch)
2018-12-08 23:47:05.880759: step 11420, G loss = 3.32, new loss = 13194.79, rb loss = 3.845 (36.8 examples/sec; 0.869 sec/batch)
2018-12-08 23:47:15.397540: step 11430, G loss = 3.37, new loss = 18564.27, rb loss = 4.004 (34.9 examples/sec; 0.918 sec/batch)
2018-12-08 23:47:23.922736: step 11440, G loss = 3.37, new loss = 16833.71, rb loss = 4.012 (39.1 examples/sec; 0.818 sec/batch)
2018-12-08 23:47:32.326383: step 11450, G loss = 3.39, new loss = -3245.14, rb loss = 3.687 (39.7 examples/sec; 0.806 sec/batch)
2018-12-08 23:47:41.129375: step 11460, G loss = 3.36, new loss = -6525.30, rb loss = 3.851 (37.8 examples/sec; 0.846 sec/batch)
2018-12-08 23:47:50.498411: step 11470, G loss = 3.27, new loss = -6986.12, rb loss = 3.537 (35.5 examples/sec; 0.902 sec/batch)
2018-12-08 23:47:59.931901: step 11480, G loss = 3.44, new loss = -7419.64, rb loss = 3.844 (35.2 examples/sec; 0.908 sec/batch)
2018-12-08 23:48:09.431008: step 11490, G loss = 3.38, new loss = 2668.31, rb loss = 3.829 (35.0 examples/sec; 0.915 sec/batch)
2018-12-08 23:48:18.479847: step 11500, G loss = 3.47, new loss = 10775.15, rb loss = 4.030 (36.8 examples/sec; 0.869 sec/batch)
Evaluation at step 11500: loss 3.32903265158, rebalanced loss 3.69454263846.
2018-12-08 23:48:44.198514: step 11510, G loss = 3.32, new loss = -3232.49, rb loss = 3.719 (12.6 examples/sec; 2.535 sec/batch)
2018-12-08 23:48:52.741753: step 11520, G loss = 3.32, new loss = 10231.48, rb loss = 3.663 (39.0 examples/sec; 0.820 sec/batch)
2018-12-08 23:49:01.104002: step 11530, G loss = 3.24, new loss = -8232.84, rb loss = 3.521 (39.9 examples/sec; 0.801 sec/batch)
2018-12-08 23:49:09.959942: step 11540, G loss = 3.34, new loss = -8183.90, rb loss = 3.745 (37.5 examples/sec; 0.852 sec/batch)
2018-12-08 23:49:16.582278: step 11550, G loss = 3.27, new loss = 9777.14, rb loss = 3.826 (50.8 examples/sec; 0.629 sec/batch)
2018-12-08 23:49:23.167077: step 11560, G loss = 3.31, new loss = 32.88, rb loss = 3.591 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:49:29.711726: step 11570, G loss = 3.30, new loss = -6140.50, rb loss = 3.744 (51.4 examples/sec; 0.622 sec/batch)
2018-12-08 23:49:36.308914: step 11580, G loss = 3.26, new loss = 9313.21, rb loss = 3.870 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:49:42.967601: step 11590, G loss = 3.13, new loss = -2579.55, rb loss = 3.463 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:49:49.588258: step 11600, G loss = 3.26, new loss = -3504.66, rb loss = 3.643 (50.8 examples/sec; 0.629 sec/batch)
Evaluation at step 11600: loss 3.35922763348, rebalanced loss 3.82653988997.
2018-12-08 23:50:07.220436: step 11610, G loss = 3.41, new loss = 28019.55, rb loss = 3.983 (18.5 examples/sec; 1.731 sec/batch)
2018-12-08 23:50:13.922320: step 11620, G loss = 3.41, new loss = 11271.55, rb loss = 3.736 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 23:50:20.544196: step 11630, G loss = 3.38, new loss = 23274.77, rb loss = 4.013 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:50:27.190421: step 11640, G loss = 3.29, new loss = -11232.17, rb loss = 3.466 (50.6 examples/sec; 0.632 sec/batch)
2018-12-08 23:50:33.798733: step 11650, G loss = 3.33, new loss = 3949.93, rb loss = 3.832 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:50:40.449953: step 11660, G loss = 3.16, new loss = -7319.08, rb loss = 3.333 (50.6 examples/sec; 0.633 sec/batch)
2018-12-08 23:50:47.076166: step 11670, G loss = 3.42, new loss = -5936.83, rb loss = 3.801 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:50:53.644591: step 11680, G loss = 3.43, new loss = -2945.42, rb loss = 3.812 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:51:00.430664: step 11690, G loss = 3.27, new loss = -14316.72, rb loss = 3.696 (49.5 examples/sec; 0.646 sec/batch)
2018-12-08 23:51:06.999455: step 11700, G loss = 3.31, new loss = 4767.63, rb loss = 3.799 (51.2 examples/sec; 0.625 sec/batch)
Evaluation at step 11700: loss 3.35099111398, rebalanced loss 3.81838200092.
2018-12-08 23:51:25.137557: step 11710, G loss = 3.30, new loss = -3131.05, rb loss = 3.686 (18.0 examples/sec; 1.781 sec/batch)
2018-12-08 23:51:31.777357: step 11720, G loss = 3.22, new loss = -3471.23, rb loss = 3.565 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:51:38.451734: step 11730, G loss = 3.24, new loss = -1461.62, rb loss = 3.639 (50.5 examples/sec; 0.634 sec/batch)
2018-12-08 23:51:45.085345: step 11740, G loss = 3.31, new loss = -2180.93, rb loss = 3.684 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:51:51.678882: step 11750, G loss = 3.31, new loss = 5675.79, rb loss = 3.657 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:51:58.216789: step 11760, G loss = 3.26, new loss = -15469.03, rb loss = 3.384 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:52:04.804540: step 11770, G loss = 3.23, new loss = 8736.64, rb loss = 3.902 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:52:11.323804: step 11780, G loss = 3.38, new loss = 14912.85, rb loss = 3.914 (51.7 examples/sec; 0.619 sec/batch)
2018-12-08 23:52:17.901241: step 11790, G loss = 3.46, new loss = 15276.62, rb loss = 4.011 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:52:24.584502: step 11800, G loss = 3.32, new loss = -5619.60, rb loss = 3.637 (50.3 examples/sec; 0.637 sec/batch)
Evaluation at step 11800: loss 3.34650684198, rebalanced loss 3.81276473204.
2018-12-08 23:52:42.427918: step 11810, G loss = 3.22, new loss = -2189.48, rb loss = 3.445 (18.3 examples/sec; 1.752 sec/batch)
2018-12-08 23:52:49.088227: step 11820, G loss = 3.23, new loss = 2596.33, rb loss = 3.713 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:52:55.864266: step 11830, G loss = 3.32, new loss = -1181.61, rb loss = 3.658 (49.7 examples/sec; 0.644 sec/batch)
2018-12-08 23:53:02.469845: step 11840, G loss = 3.20, new loss = 6277.73, rb loss = 3.779 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:53:09.014901: step 11850, G loss = 3.43, new loss = 6410.61, rb loss = 3.824 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:53:15.659886: step 11860, G loss = 3.22, new loss = -11767.27, rb loss = 3.369 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:53:22.304786: step 11870, G loss = 3.37, new loss = 657.65, rb loss = 3.759 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:53:28.834201: step 11880, G loss = 3.44, new loss = -10522.31, rb loss = 3.727 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:53:35.396463: step 11890, G loss = 3.28, new loss = -8439.43, rb loss = 3.519 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:53:41.962913: step 11900, G loss = 3.37, new loss = -893.73, rb loss = 3.673 (51.3 examples/sec; 0.623 sec/batch)
Evaluation at step 11900: loss 3.31880517801, rebalanced loss 3.76225221157.
2018-12-08 23:53:59.805171: step 11910, G loss = 3.25, new loss = -11254.55, rb loss = 3.563 (18.3 examples/sec; 1.752 sec/batch)
2018-12-08 23:54:06.404859: step 11920, G loss = 3.40, new loss = -4656.09, rb loss = 3.841 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:54:13.083624: step 11930, G loss = 3.42, new loss = 7625.00, rb loss = 3.918 (50.4 examples/sec; 0.635 sec/batch)
2018-12-08 23:54:19.816866: step 11940, G loss = 3.39, new loss = 12666.48, rb loss = 3.876 (50.1 examples/sec; 0.639 sec/batch)
2018-12-08 23:54:26.415164: step 11950, G loss = 3.26, new loss = -13270.74, rb loss = 3.638 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:54:33.014461: step 11960, G loss = 3.36, new loss = 15172.27, rb loss = 3.774 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:54:39.587805: step 11970, G loss = 3.33, new loss = -16117.20, rb loss = 3.610 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:54:46.172828: step 11980, G loss = 3.33, new loss = -14961.61, rb loss = 3.567 (51.1 examples/sec; 0.626 sec/batch)
2018-12-08 23:54:52.908884: step 11990, G loss = 3.16, new loss = -29540.08, rb loss = 3.493 (49.9 examples/sec; 0.641 sec/batch)
2018-12-08 23:54:59.527705: step 12000, G loss = 3.36, new loss = 1798.01, rb loss = 3.900 (50.9 examples/sec; 0.629 sec/batch)
Evaluation at step 12000: loss 3.35076547464, rebalanced loss 3.76708256404.
2018-12-08 23:55:23.142401: step 12010, G loss = 3.32, new loss = -9483.94, rb loss = 3.692 (13.7 examples/sec; 2.329 sec/batch)
2018-12-08 23:55:29.768940: step 12020, G loss = 3.36, new loss = -4315.44, rb loss = 3.757 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:55:36.422815: step 12030, G loss = 3.37, new loss = -10960.57, rb loss = 3.724 (50.7 examples/sec; 0.631 sec/batch)
2018-12-08 23:55:43.037174: step 12040, G loss = 3.26, new loss = -11766.72, rb loss = 3.602 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:55:49.631896: step 12050, G loss = 3.26, new loss = -20693.23, rb loss = 3.416 (51.1 examples/sec; 0.627 sec/batch)
2018-12-08 23:55:56.259771: step 12060, G loss = 3.30, new loss = 5704.98, rb loss = 3.773 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:56:02.847399: step 12070, G loss = 3.20, new loss = -8419.71, rb loss = 3.487 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:56:09.396381: step 12080, G loss = 3.19, new loss = -12227.23, rb loss = 3.488 (51.4 examples/sec; 0.623 sec/batch)
2018-12-08 23:56:15.898463: step 12090, G loss = 3.26, new loss = 4287.37, rb loss = 3.593 (51.8 examples/sec; 0.617 sec/batch)
2018-12-08 23:56:22.435827: step 12100, G loss = 3.32, new loss = 27406.56, rb loss = 3.824 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 12100: loss 3.30710070133, rebalanced loss 3.71442558765.
2018-12-08 23:56:40.043977: step 12110, G loss = 3.40, new loss = 1481.36, rb loss = 3.756 (18.5 examples/sec; 1.728 sec/batch)
2018-12-08 23:56:46.569321: step 12120, G loss = 3.32, new loss = 3669.07, rb loss = 3.766 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:56:53.140674: step 12130, G loss = 3.40, new loss = -1082.37, rb loss = 3.739 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:56:59.736479: step 12140, G loss = 3.36, new loss = 4120.29, rb loss = 3.795 (50.9 examples/sec; 0.628 sec/batch)
2018-12-08 23:57:06.283210: step 12150, G loss = 3.39, new loss = 7054.33, rb loss = 3.823 (51.5 examples/sec; 0.622 sec/batch)
2018-12-08 23:57:12.869664: step 12160, G loss = 3.54, new loss = 17796.74, rb loss = 4.175 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:57:19.458811: step 12170, G loss = 3.27, new loss = -3987.83, rb loss = 3.744 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:57:26.028749: step 12180, G loss = 3.29, new loss = -6862.50, rb loss = 3.623 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:57:32.596569: step 12190, G loss = 3.27, new loss = 1289.95, rb loss = 3.605 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:57:39.094573: step 12200, G loss = 3.36, new loss = 1676.56, rb loss = 3.776 (51.9 examples/sec; 0.617 sec/batch)
Evaluation at step 12200: loss 3.34555151463, rebalanced loss 3.80078767935.
2018-12-08 23:57:56.983891: step 12210, G loss = 3.35, new loss = 2167.58, rb loss = 4.072 (18.2 examples/sec; 1.756 sec/batch)
2018-12-08 23:58:03.523971: step 12220, G loss = 3.27, new loss = -8968.12, rb loss = 3.526 (51.5 examples/sec; 0.621 sec/batch)
2018-12-08 23:58:10.146516: step 12230, G loss = 3.32, new loss = 24819.94, rb loss = 3.976 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:58:16.999240: step 12240, G loss = 3.20, new loss = -10365.71, rb loss = 3.462 (49.0 examples/sec; 0.654 sec/batch)
2018-12-08 23:58:23.611783: step 12250, G loss = 3.34, new loss = 4376.47, rb loss = 3.833 (50.8 examples/sec; 0.630 sec/batch)
2018-12-08 23:58:30.167296: step 12260, G loss = 3.47, new loss = 12019.28, rb loss = 4.061 (51.3 examples/sec; 0.624 sec/batch)
2018-12-08 23:58:36.785543: step 12270, G loss = 3.26, new loss = -23062.86, rb loss = 3.416 (50.9 examples/sec; 0.629 sec/batch)
2018-12-08 23:58:43.589288: step 12280, G loss = 3.32, new loss = -1049.74, rb loss = 3.801 (49.4 examples/sec; 0.648 sec/batch)
2018-12-08 23:58:50.165448: step 12290, G loss = 3.43, new loss = -4858.95, rb loss = 3.822 (51.2 examples/sec; 0.625 sec/batch)
2018-12-08 23:58:56.722979: step 12300, G loss = 3.33, new loss = -2337.64, rb loss = 3.727 (51.4 examples/sec; 0.623 sec/batch)
Evaluation at step 12300: loss 3.33146117528, rebalanced loss 3.76215991974.
2018-12-08 23:59:14.538534: step 12310, G loss = 3.37, new loss = 34593.07, rb loss = 4.065 (18.3 examples/sec; 1.749 sec/batch)
2018-12-08 23:59:21.123171: step 12320, G loss = 3.42, new loss = 21010.08, rb loss = 4.069 (51.2 examples/sec; 0.626 sec/batch)
2018-12-08 23:59:27.802038: step 12330, G loss = 3.23, new loss = -3205.78, rb loss = 3.506 (50.3 examples/sec; 0.636 sec/batch)
2018-12-08 23:59:34.400668: step 12340, G loss = 3.29, new loss = -3874.30, rb loss = 3.735 (51.0 examples/sec; 0.628 sec/batch)
2018-12-08 23:59:40.997785: step 12350, G loss = 3.44, new loss = 2296.62, rb loss = 3.770 (51.0 examples/sec; 0.627 sec/batch)
2018-12-08 23:59:47.525837: step 12360, G loss = 3.16, new loss = 404.94, rb loss = 3.436 (51.6 examples/sec; 0.621 sec/batch)
2018-12-08 23:59:54.066132: step 12370, G loss = 3.31, new loss = -7985.39, rb loss = 3.691 (51.5 examples/sec; 0.621 sec/batch)
2018-12-09 00:00:00.622211: step 12380, G loss = 3.36, new loss = 4461.97, rb loss = 3.741 (51.4 examples/sec; 0.623 sec/batch)
2018-12-09 00:00:07.119721: step 12390, G loss = 3.25, new loss = -12224.51, rb loss = 3.494 (51.8 examples/sec; 0.617 sec/batch)
2018-12-09 00:00:13.612122: step 12400, G loss = 3.22, new loss = -9164.11, rb loss = 3.493 (52.0 examples/sec; 0.616 sec/batch)
Evaluation at step 12400: loss 3.32120548884, rebalanced loss 3.7863664786.
2018-12-09 00:00:30.992569: step 12410, G loss = 3.24, new loss = 1027.56, rb loss = 3.796 (18.8 examples/sec; 1.706 sec/batch)
2018-12-09 00:00:37.604144: step 12420, G loss = 3.18, new loss = -16667.29, rb loss = 3.435 (50.9 examples/sec; 0.629 sec/batch)
2018-12-09 00:00:44.184952: step 12430, G loss = 3.29, new loss = 10122.21, rb loss = 3.729 (51.1 examples/sec; 0.626 sec/batch)
2018-12-09 00:00:50.759983: step 12440, G loss = 3.23, new loss = -16537.97, rb loss = 3.550 (51.2 examples/sec; 0.625 sec/batch)
2018-12-09 00:00:57.318508: step 12450, G loss = 3.33, new loss = -12577.29, rb loss = 3.560 (51.3 examples/sec; 0.624 sec/batch)
2018-12-09 00:01:03.853415: step 12460, G loss = 3.23, new loss = 6236.03, rb loss = 3.593 (51.6 examples/sec; 0.620 sec/batch)
2018-12-09 00:01:10.473634: step 12470, G loss = 3.40, new loss = 16833.65, rb loss = 3.930 (50.8 examples/sec; 0.630 sec/batch)
2018-12-09 00:01:17.213174: step 12480, G loss = 3.27, new loss = -1972.10, rb loss = 3.700 (49.9 examples/sec; 0.641 sec/batch)
2018-12-09 00:01:23.732058: step 12490, G loss = 3.22, new loss = -766.42, rb loss = 3.723 (51.6 examples/sec; 0.620 sec/batch)
2018-12-09 00:01:30.477169: step 12500, G loss = 3.25, new loss = -11746.51, rb loss = 3.525 (49.8 examples/sec; 0.643 sec/batch)
Evaluation at step 12500: loss 3.34369533857, rebalanced loss 3.77572307587.
2018-12-09 00:01:48.457230: step 12510, G loss = 3.37, new loss = -3094.03, rb loss = 3.626 (18.1 examples/sec; 1.765 sec/batch)
2018-12-09 00:01:54.947562: step 12520, G loss = 3.33, new loss = -4931.75, rb loss = 3.687 (51.8 examples/sec; 0.618 sec/batch)
2018-12-09 00:02:01.394179: step 12530, G loss = 3.31, new loss = 6522.51, rb loss = 3.730 (52.2 examples/sec; 0.613 sec/batch)
2018-12-09 00:02:07.850157: step 12540, G loss = 3.42, new loss = -950.96, rb loss = 3.779 (52.2 examples/sec; 0.613 sec/batch)
2018-12-09 00:02:14.339617: step 12550, G loss = 3.41, new loss = 7118.11, rb loss = 3.702 (51.9 examples/sec; 0.616 sec/batch)
2018-12-09 00:02:20.913999: step 12560, G loss = 3.21, new loss = -9841.45, rb loss = 3.713 (51.2 examples/sec; 0.625 sec/batch)
2018-12-09 00:02:27.470671: step 12570, G loss = 3.33, new loss = 6610.52, rb loss = 3.730 (51.3 examples/sec; 0.623 sec/batch)
2018-12-09 00:02:34.058550: step 12580, G loss = 3.38, new loss = 15604.60, rb loss = 3.967 (51.1 examples/sec; 0.626 sec/batch)
2018-12-09 00:02:40.717062: step 12590, G loss = 3.43, new loss = 5394.75, rb loss = 3.883 (50.5 examples/sec; 0.634 sec/batch)
2018-12-09 00:02:47.305613: step 12600, G loss = 3.49, new loss = 3115.00, rb loss = 4.038 (51.1 examples/sec; 0.626 sec/batch)
Evaluation at step 12600: loss 3.33637119929, rebalanced loss 3.77955303987.
2018-12-09 00:03:04.801007: step 12610, G loss = 3.22, new loss = 47.53, rb loss = 3.611 (18.6 examples/sec; 1.717 sec/batch)
2018-12-09 00:03:11.272710: step 12620, G loss = 3.23, new loss = -9941.80, rb loss = 3.506 (52.0 examples/sec; 0.616 sec/batch)
2018-12-09 00:03:17.838159: step 12630, G loss = 3.36, new loss = -5833.91, rb loss = 3.790 (51.2 examples/sec; 0.625 sec/batch)
2018-12-09 00:03:24.410268: step 12640, G loss = 3.40, new loss = 18540.22, rb loss = 3.956 (51.1 examples/sec; 0.626 sec/batch)
2018-12-09 00:03:31.002970: step 12650, G loss = 3.24, new loss = -6114.70, rb loss = 3.614 (51.0 examples/sec; 0.628 sec/batch)
2018-12-09 00:03:37.535613: step 12660, G loss = 3.18, new loss = -18471.84, rb loss = 3.349 (51.5 examples/sec; 0.621 sec/batch)
2018-12-09 00:03:44.052702: step 12670, G loss = 3.27, new loss = -5621.75, rb loss = 3.406 (51.6 examples/sec; 0.620 sec/batch)
2018-12-09 00:03:50.597284: step 12680, G loss = 3.39, new loss = 288.59, rb loss = 3.852 (51.4 examples/sec; 0.622 sec/batch)
2018-12-09 00:03:57.112871: step 12690, G loss = 3.22, new loss = -8103.97, rb loss = 3.552 (51.6 examples/sec; 0.621 sec/batch)
2018-12-09 00:04:03.614120: step 12700, G loss = 3.37, new loss = 12388.61, rb loss = 3.820 (51.8 examples/sec; 0.617 sec/batch)
Evaluation at step 12700: loss 3.33120411237, rebalanced loss 3.81024815241.
2018-12-09 00:04:20.960182: step 12710, G loss = 3.31, new loss = 1470.52, rb loss = 3.750 (18.8 examples/sec; 1.703 sec/batch)
2018-12-09 00:04:27.546956: step 12720, G loss = 3.28, new loss = 7286.11, rb loss = 3.607 (51.1 examples/sec; 0.626 sec/batch)
2018-12-09 00:04:34.092783: step 12730, G loss = 3.33, new loss = 14453.19, rb loss = 3.670 (51.6 examples/sec; 0.620 sec/batch)
2018-12-09 00:04:40.598609: step 12740, G loss = 3.33, new loss = -7075.92, rb loss = 3.575 (51.6 examples/sec; 0.620 sec/batch)
2018-12-09 00:04:47.130833: step 12750, G loss = 3.27, new loss = -4137.34, rb loss = 3.600 (51.5 examples/sec; 0.621 sec/batch)
2018-12-09 00:04:53.698665: step 12760, G loss = 3.25, new loss = -3915.45, rb loss = 3.775 (51.3 examples/sec; 0.624 sec/batch)
2018-12-09 00:05:00.299052: step 12770, G loss = 3.39, new loss = -2592.74, rb loss = 3.723 (51.1 examples/sec; 0.626 sec/batch)
2018-12-09 00:05:07.084385: step 12780, G loss = 3.23, new loss = -8160.50, rb loss = 3.393 (49.5 examples/sec; 0.646 sec/batch)
2018-12-09 00:05:13.764164: step 12790, G loss = 3.29, new loss = 6215.46, rb loss = 3.587 (50.4 examples/sec; 0.635 sec/batch)
2018-12-09 00:05:20.296052: step 12800, G loss = 3.30, new loss = 4824.54, rb loss = 3.811 (51.5 examples/sec; 0.621 sec/batch)
Evaluation at step 12800: loss 3.32998433908, rebalanced loss 3.72985535463.
2018-12-09 00:05:37.979708: step 12810, G loss = 3.24, new loss = -9026.47, rb loss = 3.374 (18.4 examples/sec; 1.736 sec/batch)
2018-12-09 00:05:44.582158: step 12820, G loss = 3.33, new loss = -3545.97, rb loss = 3.446 (50.9 examples/sec; 0.629 sec/batch)
2018-12-09 00:05:51.180961: step 12830, G loss = 3.26, new loss = -3367.90, rb loss = 3.488 (51.0 examples/sec; 0.627 sec/batch)
2018-12-09 00:05:57.671129: step 12840, G loss = 3.24, new loss = -4689.23, rb loss = 3.601 (51.9 examples/sec; 0.617 sec/batch)
2018-12-09 00:06:04.222134: step 12850, G loss = 3.39, new loss = 24965.32, rb loss = 3.922 (51.4 examples/sec; 0.622 sec/batch)
2018-12-09 00:06:10.759170: step 12860, G loss = 3.48, new loss = 28175.81, rb loss = 4.209 (51.7 examples/sec; 0.619 sec/batch)
2018-12-09 00:06:17.417623: step 12870, G loss = 3.27, new loss = 9681.55, rb loss = 3.713 (50.4 examples/sec; 0.635 sec/batch)
2018-12-09 00:06:23.964647: step 12880, G loss = 3.26, new loss = -121.52, rb loss = 3.585 (51.4 examples/sec; 0.623 sec/batch)
2018-12-09 00:06:30.560851: step 12890, G loss = 3.39, new loss = 5466.87, rb loss = 3.773 (51.0 examples/sec; 0.627 sec/batch)
2018-12-09 00:06:37.177170: step 12900, G loss = 3.26, new loss = 4225.62, rb loss = 3.728 (50.8 examples/sec; 0.629 sec/batch)
Evaluation at step 12900: loss 3.36232461929, rebalanced loss 3.77593341668.
2018-12-09 00:06:54.542410: step 12910, G loss = 3.40, new loss = 10916.01, rb loss = 4.009 (18.8 examples/sec; 1.704 sec/batch)
2018-12-09 00:07:01.080548: step 12920, G loss = 3.35, new loss = -11465.45, rb loss = 3.702 (51.5 examples/sec; 0.621 sec/batch)
2018-12-09 00:07:07.704253: step 12930, G loss = 3.26, new loss = 139.09, rb loss = 3.616 (50.7 examples/sec; 0.631 sec/batch)
2018-12-09 00:07:14.197603: step 12940, G loss = 3.41, new loss = -1372.04, rb loss = 3.889 (51.9 examples/sec; 0.617 sec/batch)
2018-12-09 00:07:20.699605: step 12950, G loss = 3.38, new loss = 24032.21, rb loss = 4.105 (51.7 examples/sec; 0.619 sec/batch)
2018-12-09 00:07:27.146419: step 12960, G loss = 3.30, new loss = -1364.11, rb loss = 3.652 (52.3 examples/sec; 0.612 sec/batch)
2018-12-09 00:07:33.668591: step 12970, G loss = 3.39, new loss = -12728.47, rb loss = 3.717 (51.6 examples/sec; 0.620 sec/batch)
2018-12-09 00:07:40.162414: step 12980, G loss = 3.29, new loss = -12078.60, rb loss = 3.534 (51.8 examples/sec; 0.617 sec/batch)
2018-12-09 00:07:46.629884: step 12990, G loss = 3.35, new loss = 8201.62, rb loss = 3.763 (52.1 examples/sec; 0.615 sec/batch)
2018-12-09 00:07:53.192309: step 13000, G loss = 3.15, new loss = -6849.59, rb loss = 3.410 (51.5 examples/sec; 0.622 sec/batch)
Evaluation at step 13000: loss 3.30878814856, rebalanced loss 3.71302500566.
